{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincenthaywood/Cerebri/blob/main/FluxGym_ipynb2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I-HADozm4sB"
      },
      "source": [
        "# **FluxGym Colab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmV1zQMole6d"
      },
      "source": [
        "**Important Notice**\n",
        "\n",
        "Please be aware that this Colab notebook is a work in progress. Model training can be time-consuming, and you may want to consider a Colab Pro membership for extensive training sessions.\n",
        "\n",
        "We are working on improving training efficiency and will update the notebook as advancements are made from the original developers. Thank you for your understanding!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-39F5xHjJ2m"
      },
      "source": [
        "# **Git Clone the Flux Gym and Kohya-SS sd-scripts Github Repository**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lU6VoX3zs66v",
        "outputId": "30dc04f8-ccdd-45b0-bf6a-15499a74fc09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fluxgym-Colab'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 107 (delta 54), reused 32 (delta 32), pack-reused 40 (from 2)\u001b[K\n",
            "Receiving objects: 100% (107/107), 12.41 MiB | 14.74 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/TheLocalLab/fluxgym-Colab.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F1U5UZJltP30",
        "outputId": "64b15e01-8552-4f26-d141-30834112d5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab\n",
            "Cloning into 'sd-scripts'...\n",
            "remote: Enumerating objects: 9659, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 9659 (delta 15), reused 5 (delta 5), pack-reused 9634 (from 2)\u001b[K\n",
            "Receiving objects: 100% (9659/9659), 11.62 MiB | 15.64 MiB/s, done.\n",
            "Resolving deltas: 100% (6933/6933), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/fluxgym-Colab/\n",
        "!git clone -b sd3 https://github.com/kohya-ss/sd-scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQLG4s_5j5HM"
      },
      "source": [
        "# **Install each projects dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "eD7Yf7B5tWVa",
        "outputId": "a4a5a926-966b-49fc-fd76-a389fed2b25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab/sd-scripts\n",
            "Obtaining file:///content/fluxgym-Colab/sd-scripts (from -r requirements.txt (line 48))\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.33.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting transformers==4.44.0 (from -r requirements.txt (line 2))\n",
            "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers==0.25.0 (from diffusers[torch]==0.25.0->-r requirements.txt (line 3))\n",
            "  Downloading diffusers-0.25.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting ftfy==6.1.1 (from -r requirements.txt (line 4))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opencv-python==4.8.1.78 (from -r requirements.txt (line 6))\n",
            "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting einops==0.7.0 (from -r requirements.txt (line 7))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pytorch-lightning==1.9.0 (from -r requirements.txt (line 8))\n",
            "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting bitsandbytes==0.44.0 (from -r requirements.txt (line 9))\n",
            "  Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting lion-pytorch==0.0.6 (from -r requirements.txt (line 10))\n",
            "  Downloading lion_pytorch-0.0.6-py3-none-any.whl.metadata (620 bytes)\n",
            "Collecting schedulefree==1.4 (from -r requirements.txt (line 11))\n",
            "  Downloading schedulefree-1.4.tar.gz (22 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-optimizer==3.5.0 (from -r requirements.txt (line 12))\n",
            "  Downloading pytorch_optimizer-3.5.0-py3-none-any.whl.metadata (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prodigy-plus-schedule-free==1.9.0 (from -r requirements.txt (line 13))\n",
            "  Downloading prodigy_plus_schedule_free-1.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting prodigyopt==1.1.2 (from -r requirements.txt (line 14))\n",
            "  Downloading prodigyopt-1.1.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.18.0)\n",
            "Collecting safetensors==0.4.4 (from -r requirements.txt (line 16))\n",
            "  Downloading safetensors-0.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting altair==4.2.2 (from -r requirements.txt (line 18))\n",
            "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting easygui==0.98.3 (from -r requirements.txt (line 19))\n",
            "  Downloading easygui-0.98.3-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (0.10.2)\n",
            "Collecting voluptuous==0.13.1 (from -r requirements.txt (line 21))\n",
            "  Downloading voluptuous-0.13.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting huggingface-hub==0.24.5 (from -r requirements.txt (line 22))\n",
            "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: imagesize==1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (1.4.1)\n",
            "Collecting numpy<=2.0 (from -r requirements.txt (line 25))\n",
            "  Downloading numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich==13.7.0 (from -r requirements.txt (line 44))\n",
            "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 46)) (0.2.0)\n",
            "Collecting numpy<=2.0 (from -r requirements.txt (line 25))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0->-r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.0->-r requirements.txt (line 2))\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (8.7.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 4)) (0.2.13)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2025.3.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (4.14.0)\n",
            "Collecting lightning-utilities>=0.4.2 (from pytorch-lightning==1.9.0->-r requirements.txt (line 8))\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2->-r requirements.txt (line 18)) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2->-r requirements.txt (line 18)) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2->-r requirements.txt (line 18)) (4.24.0)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2->-r requirements.txt (line 18)) (2.2.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2->-r requirements.txt (line 18)) (0.12.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.0->-r requirements.txt (line 44)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.0->-r requirements.txt (line 44)) (2.19.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 15)) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 15)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 15)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 15)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 15)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (3.11.15)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 18)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 18)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 18)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.txt (line 18)) (0.25.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.0->-r requirements.txt (line 44)) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 18)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 18)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.txt (line 18)) (2025.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1)) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.33.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 15)) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.25.0->diffusers[torch]==0.25.0->-r requirements.txt (line 3)) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0->-r requirements.txt (line 2)) (2025.6.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0->-r requirements.txt (line 8)) (1.20.1)\n",
            "Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lion_pytorch-0.0.6-py3-none-any.whl (4.2 kB)\n",
            "Downloading pytorch_optimizer-3.5.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.2/239.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prodigy_plus_schedule_free-1.9.0-py3-none-any.whl (22 kB)\n",
            "Downloading prodigyopt-1.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading safetensors-0.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.4/435.4 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\n",
            "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: schedulefree\n",
            "  Building wheel for schedulefree (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for schedulefree: filename=schedulefree-1.4-py3-none-any.whl size=39334 sha256=f7040ed5b88cd3423aa38c9bbeabb402a1f3e18acce4ddf55911fe534ab57124\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/77/aa/edc982c812bbfb7d516f4de2b373eaafe450b27cd7e4f041ea\n",
            "Successfully built schedulefree\n",
            "Installing collected packages: voluptuous, library, easygui, schedulefree, safetensors, prodigyopt, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, lightning-utilities, ftfy, einops, rich, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, diffusers, transformers, altair, torchmetrics, pytorch-optimizer, prodigy-plus-schedule-free, lion-pytorch, bitsandbytes, accelerate, pytorch-lightning\n",
            "  Running setup.py develop for library\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.5.3\n",
            "    Uninstalling safetensors-0.5.3:\n",
            "      Successfully uninstalled safetensors-0.5.3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.1\n",
            "    Uninstalling einops-0.8.1:\n",
            "      Successfully uninstalled einops-0.8.1\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.33.0\n",
            "    Uninstalling huggingface-hub-0.33.0:\n",
            "      Successfully uninstalled huggingface-hub-0.33.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.33.1\n",
            "    Uninstalling diffusers-0.33.1:\n",
            "      Successfully uninstalled diffusers-0.33.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.4\n",
            "    Uninstalling transformers-4.52.4:\n",
            "      Successfully uninstalled transformers-4.52.4\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 5.5.0\n",
            "    Uninstalling altair-5.5.0:\n",
            "      Successfully uninstalled altair-5.5.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.7.0\n",
            "    Uninstalling accelerate-1.7.0:\n",
            "      Successfully uninstalled accelerate-1.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "peft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.24.5 which is incompatible.\n",
            "pymc 5.23.0 requires rich>=13.7.1, but you have rich 13.7.0 which is incompatible.\n",
            "gradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.24.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.33.0 altair-4.2.2 bitsandbytes-0.44.0 diffusers-0.25.0 easygui-0.98.3 einops-0.7.0 ftfy-6.1.1 huggingface-hub-0.24.5 library-0.0.0 lightning-utilities-0.14.3 lion-pytorch-0.0.6 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencv-python-4.8.1.78 prodigy-plus-schedule-free-1.9.0 prodigyopt-1.1.2 pytorch-lightning-1.9.0 pytorch-optimizer-3.5.0 rich-13.7.0 safetensors-0.4.4 schedulefree-1.4 tokenizers-0.19.1 torchmetrics-1.7.3 transformers-4.44.0 voluptuous-0.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "644488b2e5ea4ace87223142f531267c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%cd /content/fluxgym-Colab/sd-scripts/\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "keb-H6-tu6d8",
        "outputId": "aa0195f2-5482-4bff-dd99-b4a73d204c8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab\n",
            "Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements.txt (line 2))\n",
            "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-w4oe8ijb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-w4oe8ijb\n",
            "  Resolved https://github.com/huggingface/diffusers.git to commit 0874dd04dc1bb359053935109dc95483218b086f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio_logsview@ https://huggingface.co/spaces/cocktailpeanut/gradio_logsview/resolve/main/gradio_logsview-0.0.17-py3-none-any.whl (from -r requirements.txt (line 3))\n",
            "  Downloading https://huggingface.co/spaces/cocktailpeanut/gradio_logsview/resolve/main/gradio_logsview-0.0.17-py3-none-any.whl (324 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.2/324.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (0.4.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.44.0)\n",
            "Collecting lycoris-lora==1.8.3 (from -r requirements.txt (line 5))\n",
            "  Downloading lycoris_lora-1.8.3.tar.gz (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatten_json (from -r requirements.txt (line 6))\n",
            "  Downloading flatten_json-0.1.14-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (6.0.2)\n",
            "Collecting oyaml (from -r requirements.txt (line 8))\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.18.0)\n",
            "Collecting kornia (from -r requirements.txt (line 10))\n",
            "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting invisible-watermark (from -r requirements.txt (line 11))\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.33.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.10.2)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.0.8)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.11.7)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (2.3.0)\n",
            "Collecting k-diffusion (from -r requirements.txt (line 18))\n",
            "  Downloading k_diffusion-0.1.1.post1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting open_clip_torch (from -r requirements.txt (line 19))\n",
            "  Downloading open_clip_torch-2.32.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (1.0.15)\n",
            "Requirement already satisfied: prodigyopt in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (1.1.2)\n",
            "Collecting controlnet_aux==0.0.7 (from -r requirements.txt (line 22))\n",
            "  Downloading controlnet_aux-0.0.7.tar.gz (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.4/202.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv (from -r requirements.txt (line 23))\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (0.44.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (0.1.9)\n",
            "Collecting lpips (from -r requirements.txt (line 26))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pytorch_fid (from -r requirements.txt (line 27))\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting optimum-quanto (from -r requirements.txt (line 28))\n",
            "  Downloading optimum_quanto-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (0.2.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (0.24.5)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (0.15.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (5.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (8.0.4)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from lycoris-lora==1.8.3->-r requirements.txt (line 5)) (2.6.0+cu124)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (8.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (1.15.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (4.8.1.78)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (3.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (11.2.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (0.25.2)\n",
            "Collecting huggingface_hub (from -r requirements.txt (line 30))\n",
            "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Collecting gradio (from -r requirements.txt (line 32))\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 4)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from flatten_json->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.1.3)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia->-r requirements.txt (line 10))\n",
            "  Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from invisible-watermark->-r requirements.txt (line 11)) (1.8.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 13)) (5.9.5)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations->-r requirements.txt (line 15)) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->-r requirements.txt (line 15)) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->-r requirements.txt (line 15)) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->-r requirements.txt (line 15)) (6.4.9)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 16)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 16)) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 16)) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 16)) (0.4.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 17)) (4.9.3)\n",
            "Collecting clean-fid (from k-diffusion->-r requirements.txt (line 18))\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->-r requirements.txt (line 18))\n",
            "  Downloading clip_anytorch-2.6.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting dctorch (from k-diffusion->-r requirements.txt (line 18))\n",
            "  Downloading dctorch-0.1.2-py3-none-any.whl.metadata (607 bytes)\n",
            "Collecting jsonmerge (from k-diffusion->-r requirements.txt (line 18))\n",
            "  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchdiffeq (from k-diffusion->-r requirements.txt (line 18))\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde (from k-diffusion->-r requirements.txt (line 18))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r requirements.txt (line 18)) (0.20.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from open_clip_torch->-r requirements.txt (line 19)) (6.1.1)\n",
            "Collecting ninja (from optimum-quanto->-r requirements.txt (line 28))\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r requirements.txt (line 30)) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r requirements.txt (line 30)) (1.1.3)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 32))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.6.0)\n",
            "Collecting gradio-client==1.3.0 (from gradio->-r requirements.txt (line 32))\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 32))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (2.2.2)\n",
            "Collecting Pillow (from controlnet_aux==0.0.7->-r requirements.txt (line 22))\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.11.13)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (2.10.0)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 32))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.16.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (2.4.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.34.3)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio->-r requirements.txt (line 32))\n",
            "  Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->-r requirements.txt (line 33)) (1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 32)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 32)) (1.3.1)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1.0->gradio->-r requirements.txt (line 32)) (0.46.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 32)) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 32)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 32)) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 32)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 32)) (2025.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (13.7.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch->-r requirements.txt (line 19)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->controlnet_aux==0.0.7->-r requirements.txt (line 22)) (3.23.0)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.11/dist-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 18)) (4.24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->controlnet_aux==0.0.7->-r requirements.txt (line 22)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->controlnet_aux==0.0.7->-r requirements.txt (line 22)) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->controlnet_aux==0.0.7->-r requirements.txt (line 22)) (0.4)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->k-diffusion->-r requirements.txt (line 18))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 18)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 18)) (4.3.8)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 18)) (2.30.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 18)) (1.3.6)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 18)) (4.0.12)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 18)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 18)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 18)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 18)) (0.25.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (2.19.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 18)) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (0.1.2)\n",
            "Downloading flatten_json-0.1.14-py3-none-any.whl (8.0 kB)\n",
            "Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading k_diffusion-0.1.1.post1-py3-none-any.whl (33 kB)\n",
            "Downloading open_clip_torch-2.32.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading optimum_quanto-0.2.7-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.3/165.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.8/514.8 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Downloading clip_anytorch-2.6.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dctorch-0.1.2-py3-none-any.whl (2.3 kB)\n",
            "Downloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n",
            "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lycoris-lora, controlnet_aux, diffusers\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lycoris-lora: filename=lycoris_lora-1.8.3-py3-none-any.whl size=77135 sha256=ea3ff20a8fb2d87a8fb529ab820cef91c420239f81e4d48b3570f7b5eab40d6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/08/86/23334b2fa19ee75319462a0371db0501dc769a660e4ed95e33\n",
            "  Building wheel for controlnet_aux (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for controlnet_aux: filename=controlnet_aux-0.0.7-py3-none-any.whl size=274344 sha256=8f81a9d4e9dc5208ef1b5c744888966b3d6b3a6f9592736adf22b6082115dedf\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/a1/0f/79d1529bbc60d1598da66052a2c60a2a13e5ac462b5f990653\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.34.0.dev0-py3-none-any.whl size=3773900 sha256=e129d88843cf9490a54a4de21e8210e8557792ee5f782343b28dc0c999693273\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xekclmu7/wheels/d2/5c/5f/16639722ea17ecb73ab461b81718584bac08af2801619786b9\n",
            "Successfully built lycoris-lora controlnet_aux diffusers\n",
            "Installing collected packages: trampoline, websockets, tomlkit, python-dotenv, Pillow, oyaml, ninja, markupsafe, kornia_rs, flatten_json, aiofiles, huggingface_hub, gradio-client, diffusers, torchsde, torchdiffeq, optimum-quanto, kornia, jsonmerge, invisible-watermark, gradio, dctorch, pytorch_fid, lycoris-lora, lpips, gradio_logsview, clip-anytorch, clean-fid, open_clip_torch, k-diffusion, controlnet_aux\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.3\n",
            "    Uninstalling tomlkit-0.13.3:\n",
            "      Successfully uninstalled tomlkit-0.13.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.24.5\n",
            "    Uninstalling huggingface-hub-0.24.5:\n",
            "      Successfully uninstalled huggingface-hub-0.24.5\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.10.1\n",
            "    Uninstalling gradio_client-1.10.1:\n",
            "      Successfully uninstalled gradio_client-1.10.1\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.25.0\n",
            "    Uninstalling diffusers-0.25.0:\n",
            "      Successfully uninstalled diffusers-0.25.0\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.31.0\n",
            "    Uninstalling gradio-5.31.0:\n",
            "      Successfully uninstalled gradio-5.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.7.5 requires websockets>=14.0, but you have websockets 12.0 which is incompatible.\n",
            "yfinance 0.2.63 requires websockets>=13.0, but you have websockets 12.0 which is incompatible.\n",
            "google-genai 1.20.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.4.0 aiofiles-23.2.1 clean-fid-0.1.35 clip-anytorch-2.6.0 controlnet_aux-0.0.7 dctorch-0.1.2 diffusers-0.34.0.dev0 flatten_json-0.1.14 gradio-4.44.1 gradio-client-1.3.0 gradio_logsview-0.0.17 huggingface_hub-0.33.0 invisible-watermark-0.2.0 jsonmerge-1.9.2 k-diffusion-0.1.1.post1 kornia-0.8.1 kornia_rs-0.1.9 lpips-0.1.4 lycoris-lora-1.8.3 markupsafe-2.1.5 ninja-1.11.1.4 open_clip_torch-2.32.0 optimum-quanto-0.2.7 oyaml-1.0 python-dotenv-1.1.0 pytorch_fid-0.3.0 tomlkit-0.12.0 torchdiffeq-0.2.5 torchsde-0.2.6 trampoline-0.1.2 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "%cd /content/fluxgym-Colab/\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NxoJxm3zuBDL",
        "outputId": "3d2ebcb5-10a9-47e5-aa87-e8465fa408f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu121\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (2.1.5)\n",
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu121\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torch --index-url https://download.pytorch.org/whl/nightly/cu121\n",
        "!pip install -U torchvision --index-url https://download.pytorch.org/whl/nightly/cu121\n",
        "!pip install -U torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qsySAjNj-PG"
      },
      "source": [
        "# **Download the models needed for training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lwZGQcOD5Rpi",
        "outputId": "7e77097d-aaf0-4f36-df3c-af7c036eaf3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-20 22:20:26--  https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/flux1-dev.sft?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.103, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/e6/1b/e61b51323e49f08f24e9281f70900db08a8c978b7ad4a4ec5c21b72296a4214b/4610115bb0c89560703c892c59ac2742fa821e60ef5871b33493ba544683abd7?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27flux1-dev.sft%3B+filename%3D%22flux1-dev.sft%22%3B&Expires=1750461626&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MTYyNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U2LzFiL2U2MWI1MTMyM2U0OWYwOGYyNGU5MjgxZjcwOTAwZGIwOGE4Yzk3OGI3YWQ0YTRlYzVjMjFiNzIyOTZhNDIxNGIvNDYxMDExNWJiMGM4OTU2MDcwM2M4OTJjNTlhYzI3NDJmYTgyMWU2MGVmNTg3MWIzMzQ5M2JhNTQ0NjgzYWJkNz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=psMyPHDgndqPbJn2KM-qDPUjss5JORLoin8tW8W5Qma5xjTn71q2ZqlqlKUQHInyMCfNPiOJPZTX0C5D6sERjEgsykZHG5NR4xtpoz8o0jLN7jCbRMGWhwBoqp6nGW0QJDg9SsEe1Or4ruN-9tVCZYzQmYio058ZaBK543j0eEeiYlHqI2B5t4x2m9gihAiWENR4MWrnXWQnPnzt%7EqgpSu5JOO2F8VDz3fxTYj00wZTaf0vA0hQ3QFdlPgbRKOgW3SlnVOTud2fc81ACpnEZR1nOIKbcSlG4YU9VZj-EEe44P6BDPA4kCO61xLfOHRbg4PYSWA2-4Pty2dBLsVc9Lg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-06-20 22:20:26--  https://cdn-lfs-us-1.hf.co/repos/e6/1b/e61b51323e49f08f24e9281f70900db08a8c978b7ad4a4ec5c21b72296a4214b/4610115bb0c89560703c892c59ac2742fa821e60ef5871b33493ba544683abd7?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27flux1-dev.sft%3B+filename%3D%22flux1-dev.sft%22%3B&Expires=1750461626&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MTYyNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U2LzFiL2U2MWI1MTMyM2U0OWYwOGYyNGU5MjgxZjcwOTAwZGIwOGE4Yzk3OGI3YWQ0YTRlYzVjMjFiNzIyOTZhNDIxNGIvNDYxMDExNWJiMGM4OTU2MDcwM2M4OTJjNTlhYzI3NDJmYTgyMWU2MGVmNTg3MWIzMzQ5M2JhNTQ0NjgzYWJkNz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=psMyPHDgndqPbJn2KM-qDPUjss5JORLoin8tW8W5Qma5xjTn71q2ZqlqlKUQHInyMCfNPiOJPZTX0C5D6sERjEgsykZHG5NR4xtpoz8o0jLN7jCbRMGWhwBoqp6nGW0QJDg9SsEe1Or4ruN-9tVCZYzQmYio058ZaBK543j0eEeiYlHqI2B5t4x2m9gihAiWENR4MWrnXWQnPnzt%7EqgpSu5JOO2F8VDz3fxTYj00wZTaf0vA0hQ3QFdlPgbRKOgW3SlnVOTud2fc81ACpnEZR1nOIKbcSlG4YU9VZj-EEe44P6BDPA4kCO61xLfOHRbg4PYSWA2-4Pty2dBLsVc9Lg__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.239.36.126, 18.239.36.68, 18.239.36.52, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.239.36.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23802932552 (22G) [binary/octet-stream]\n",
            "Saving to: ‘/content/fluxgym-Colab/models/unet/flux1-dev.sft’\n",
            "\n",
            "/content/fluxgym-Co 100%[===================>]  22.17G   248MB/s    in 7m 12s  \n",
            "\n",
            "2025-06-20 22:27:39 (52.5 MB/s) - ‘/content/fluxgym-Colab/models/unet/flux1-dev.sft’ saved [23802932552/23802932552]\n",
            "\n",
            "--2025-06-20 22:27:39--  https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.16, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/f0/72/f072b3fc381065339926f6194e8ae71b6a464d596c9495100c3c8730729ec94e/660c6f5b1abae9dc498ac2d21e1347d2abdb0cf6c0c0c8576cd796491d9a6cdd?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27clip_l.safetensors%3B+filename%3D%22clip_l.safetensors%22%3B&Expires=1750462059&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MjA1OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2YwLzcyL2YwNzJiM2ZjMzgxMDY1MzM5OTI2ZjYxOTRlOGFlNzFiNmE0NjRkNTk2Yzk0OTUxMDBjM2M4NzMwNzI5ZWM5NGUvNjYwYzZmNWIxYWJhZTlkYzQ5OGFjMmQyMWUxMzQ3ZDJhYmRiMGNmNmMwYzBjODU3NmNkNzk2NDkxZDlhNmNkZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=hu5IQVEoHaiwfoV6rUPjoqV60SnbwMILpOwauJ59SQL-5Lh2xU2QVQzQD-HkaCjMppIC11uJYrwfyImT4-Chsc-%7EtdK74oRFi%7ELBnvDgZL14NLsOvfezLkE6KCtGrvbnak%7E9HfkY5YnBd2Y1p641ILiDk0tue9eFeZsf2%7EHL1XVroylcoh6QKTaFSgn9qZRZJpP9pFSd1NN7Y6TQiTAvg6LsknN-aFbu6Bkg4%7En3LSfFXo71PtI2ESaN0MSIq%7EYffIgTlTIZ9k850X3zEMM0p6ai238sQu2mIMG9p4nMIPk86C8ZXHZBXrHXb-t2lqy30bn56ygpftZf%7EMXAJ3ltHg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-06-20 22:27:39--  https://cdn-lfs-us-1.hf.co/repos/f0/72/f072b3fc381065339926f6194e8ae71b6a464d596c9495100c3c8730729ec94e/660c6f5b1abae9dc498ac2d21e1347d2abdb0cf6c0c0c8576cd796491d9a6cdd?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27clip_l.safetensors%3B+filename%3D%22clip_l.safetensors%22%3B&Expires=1750462059&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MjA1OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2YwLzcyL2YwNzJiM2ZjMzgxMDY1MzM5OTI2ZjYxOTRlOGFlNzFiNmE0NjRkNTk2Yzk0OTUxMDBjM2M4NzMwNzI5ZWM5NGUvNjYwYzZmNWIxYWJhZTlkYzQ5OGFjMmQyMWUxMzQ3ZDJhYmRiMGNmNmMwYzBjODU3NmNkNzk2NDkxZDlhNmNkZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=hu5IQVEoHaiwfoV6rUPjoqV60SnbwMILpOwauJ59SQL-5Lh2xU2QVQzQD-HkaCjMppIC11uJYrwfyImT4-Chsc-%7EtdK74oRFi%7ELBnvDgZL14NLsOvfezLkE6KCtGrvbnak%7E9HfkY5YnBd2Y1p641ILiDk0tue9eFeZsf2%7EHL1XVroylcoh6QKTaFSgn9qZRZJpP9pFSd1NN7Y6TQiTAvg6LsknN-aFbu6Bkg4%7En3LSfFXo71PtI2ESaN0MSIq%7EYffIgTlTIZ9k850X3zEMM0p6ai238sQu2mIMG9p4nMIPk86C8ZXHZBXrHXb-t2lqy30bn56ygpftZf%7EMXAJ3ltHg__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.239.36.72, 18.239.36.126, 18.239.36.52, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.239.36.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 246144152 (235M) [binary/octet-stream]\n",
            "Saving to: ‘/content/fluxgym-Colab/models/clip/clip_l.safetensors’\n",
            "\n",
            "/content/fluxgym-Co 100%[===================>] 234.74M   261MB/s    in 0.9s    \n",
            "\n",
            "2025-06-20 22:27:40 (261 MB/s) - ‘/content/fluxgym-Colab/models/clip/clip_l.safetensors’ saved [246144152/246144152]\n",
            "\n",
            "--2025-06-20 22:27:40--  https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.16, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/f0/72/f072b3fc381065339926f6194e8ae71b6a464d596c9495100c3c8730729ec94e/7d330da4816157540d6bb7838bf63a0f02f573fc48ca4d8de34bb0cbfd514f09?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27t5xxl_fp8_e4m3fn.safetensors%3B+filename%3D%22t5xxl_fp8_e4m3fn.safetensors%22%3B&Expires=1750462060&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MjA2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2YwLzcyL2YwNzJiM2ZjMzgxMDY1MzM5OTI2ZjYxOTRlOGFlNzFiNmE0NjRkNTk2Yzk0OTUxMDBjM2M4NzMwNzI5ZWM5NGUvN2QzMzBkYTQ4MTYxNTc1NDBkNmJiNzgzOGJmNjNhMGYwMmY1NzNmYzQ4Y2E0ZDhkZTM0YmIwY2JmZDUxNGYwOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Ky7mKCpNWnugHM5DQDSXt11Meh%7EWztCRjuNErxy4fMzH2mLwKrSenZR7s9QwGM1t1vEVt4%7EellwF03%7E26vrW7BazjAH7cyZggJLkE-v2paZhZQITHpzDUMEeYChC4et6A5DYLmrTRNjYTx-h3ZDUZEM4EDtMrIt9Jx6W7w9a4Yv9XdRffEYUUgViWFm8M1YlBEZUkntavTTYOKJWpdSd2Jir4RO0Vd0hI%7E0mRlGJrdp3cSuIB2F3llqA5u4cswBQDx7lJV0xXw18vRquIxs8gco2i62NbTLNjDOerZKFnroFGFu%7E1bu3vYe12Ynqx5D2mVvVQB5Gp2W1MxyJ1uNelw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-06-20 22:27:40--  https://cdn-lfs-us-1.hf.co/repos/f0/72/f072b3fc381065339926f6194e8ae71b6a464d596c9495100c3c8730729ec94e/7d330da4816157540d6bb7838bf63a0f02f573fc48ca4d8de34bb0cbfd514f09?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27t5xxl_fp8_e4m3fn.safetensors%3B+filename%3D%22t5xxl_fp8_e4m3fn.safetensors%22%3B&Expires=1750462060&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MjA2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2YwLzcyL2YwNzJiM2ZjMzgxMDY1MzM5OTI2ZjYxOTRlOGFlNzFiNmE0NjRkNTk2Yzk0OTUxMDBjM2M4NzMwNzI5ZWM5NGUvN2QzMzBkYTQ4MTYxNTc1NDBkNmJiNzgzOGJmNjNhMGYwMmY1NzNmYzQ4Y2E0ZDhkZTM0YmIwY2JmZDUxNGYwOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Ky7mKCpNWnugHM5DQDSXt11Meh%7EWztCRjuNErxy4fMzH2mLwKrSenZR7s9QwGM1t1vEVt4%7EellwF03%7E26vrW7BazjAH7cyZggJLkE-v2paZhZQITHpzDUMEeYChC4et6A5DYLmrTRNjYTx-h3ZDUZEM4EDtMrIt9Jx6W7w9a4Yv9XdRffEYUUgViWFm8M1YlBEZUkntavTTYOKJWpdSd2Jir4RO0Vd0hI%7E0mRlGJrdp3cSuIB2F3llqA5u4cswBQDx7lJV0xXw18vRquIxs8gco2i62NbTLNjDOerZKFnroFGFu%7E1bu3vYe12Ynqx5D2mVvVQB5Gp2W1MxyJ1uNelw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.239.36.72, 18.239.36.126, 18.239.36.52, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.239.36.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4893934904 (4.6G) [binary/octet-stream]\n",
            "Saving to: ‘/content/fluxgym-Colab/models/clip/t5xxl_fp16.safetensors’\n",
            "\n",
            "/content/fluxgym-Co 100%[===================>]   4.56G   246MB/s    in 1m 55s  \n",
            "\n",
            "2025-06-20 22:29:35 (40.6 MB/s) - ‘/content/fluxgym-Colab/models/clip/t5xxl_fp16.safetensors’ saved [4893934904/4893934904]\n",
            "\n",
            "--2025-06-20 22:29:35--  https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/ae.sft?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.103, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/e6/1b/e61b51323e49f08f24e9281f70900db08a8c978b7ad4a4ec5c21b72296a4214b/afc8e28272cd15db3919bacdb6918ce9c1ed22e96cb12c4d5ed0fba823529e38?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27ae.sft%3B+filename%3D%22ae.sft%22%3B&Expires=1750462175&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MjE3NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U2LzFiL2U2MWI1MTMyM2U0OWYwOGYyNGU5MjgxZjcwOTAwZGIwOGE4Yzk3OGI3YWQ0YTRlYzVjMjFiNzIyOTZhNDIxNGIvYWZjOGUyODI3MmNkMTVkYjM5MTliYWNkYjY5MThjZTljMWVkMjJlOTZjYjEyYzRkNWVkMGZiYTgyMzUyOWUzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=FM9Ye%7Ecknrz-NQSiT4Tda1NntB60-Ch18A-kTMFMf63RmFY6YiJJiIfT83VEAUorNqRlYl8TrU38Ew9vnClj4rZAvGVqXLEcriXWWHH7Se-nQCadnSCEdw5U%7EwLjwQ6dhY3-oN-ElXFfoLlrBQfy306v8VXjYEJdPJ1ALr3r4EZp8jOnrV35m27yvmydvcjDvV1mPbydLr%7EnjdPZ7bQSJqzp0vZMt%7EHGgu6jdG1KZzRUwXt7NnOeBVCeax4-4gDewlbJFNHPdqmtuS98xeR%7EA-FS7riQ74PiPzOF2YwL%7E2C9ChNPXqafVw80krTUjWZVxpItxsmxR6AIKu1G6UkOVA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-06-20 22:29:36--  https://cdn-lfs-us-1.hf.co/repos/e6/1b/e61b51323e49f08f24e9281f70900db08a8c978b7ad4a4ec5c21b72296a4214b/afc8e28272cd15db3919bacdb6918ce9c1ed22e96cb12c4d5ed0fba823529e38?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27ae.sft%3B+filename%3D%22ae.sft%22%3B&Expires=1750462175&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MjE3NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U2LzFiL2U2MWI1MTMyM2U0OWYwOGYyNGU5MjgxZjcwOTAwZGIwOGE4Yzk3OGI3YWQ0YTRlYzVjMjFiNzIyOTZhNDIxNGIvYWZjOGUyODI3MmNkMTVkYjM5MTliYWNkYjY5MThjZTljMWVkMjJlOTZjYjEyYzRkNWVkMGZiYTgyMzUyOWUzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=FM9Ye%7Ecknrz-NQSiT4Tda1NntB60-Ch18A-kTMFMf63RmFY6YiJJiIfT83VEAUorNqRlYl8TrU38Ew9vnClj4rZAvGVqXLEcriXWWHH7Se-nQCadnSCEdw5U%7EwLjwQ6dhY3-oN-ElXFfoLlrBQfy306v8VXjYEJdPJ1ALr3r4EZp8jOnrV35m27yvmydvcjDvV1mPbydLr%7EnjdPZ7bQSJqzp0vZMt%7EHGgu6jdG1KZzRUwXt7NnOeBVCeax4-4gDewlbJFNHPdqmtuS98xeR%7EA-FS7riQ74PiPzOF2YwL%7E2C9ChNPXqafVw80krTUjWZVxpItxsmxR6AIKu1G6UkOVA__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.239.83.13, 18.239.83.59, 18.239.83.106, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.239.83.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335304388 (320M) [binary/octet-stream]\n",
            "Saving to: ‘/content/fluxgym-Colab/models/vae/ae.sft’\n",
            "\n",
            "/content/fluxgym-Co 100%[===================>] 319.77M   284MB/s    in 1.1s    \n",
            "\n",
            "2025-06-20 22:29:37 (284 MB/s) - ‘/content/fluxgym-Colab/models/vae/ae.sft’ saved [335304388/335304388]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/fluxgym-Colab/models/unet/flux1-dev.sft https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/flux1-dev.sft?download=true\n",
        "!wget -O /content/fluxgym-Colab/models/clip/clip_l.safetensors https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors?download=true\n",
        "!wget -O /content/fluxgym-Colab/models/clip/t5xxl_fp16.safetensors https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors?download=true\n",
        "!wget -O /content/fluxgym-Colab/models/vae/ae.sft https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/ae.sft?download=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMJRiYvzd5hZ",
        "outputId": "334e6ce9-c554-4153-c25c-a02477585a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab\n"
          ]
        }
      ],
      "source": [
        "%cd /content/fluxgym-Colab/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tef5XIaQksXa"
      },
      "source": [
        "# **Start the web server and click the share link**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mzJMy5sjuICj",
        "outputId": "b3541c5f-5c3f-4841-e2a0-589f90d290a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-20 22:32:55.985945: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750458776.007093    6108 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750458776.013615    6108 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-20 22:32:56.036400: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\u001b[31mERROR\u001b[0m:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 761, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 714, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 734, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 288, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 76, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 73, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 301, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 214, in run_endpoint_function\n",
            "    return await run_in_threadpool(dependant.call, **values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/concurrency.py\", line 37, in run_in_threadpool\n",
            "    return await anyio.to_thread.run_sync(func)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 431, in main\n",
            "    gradio_api_info = api_info(False)\n",
            "                      ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 460, in api_info\n",
            "    app.api_info = app.get_blocks().get_api_info()\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2785, in get_api_info\n",
            "    python_type = client_utils.json_schema_to_python_type(info)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 893, in json_schema_to_python_type\n",
            "    type_ = _json_schema_to_python_type(schema, schema.get(\"$defs\"))\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 938, in _json_schema_to_python_type\n",
            "    elements = _json_schema_to_python_type(items, defs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 908, in _json_schema_to_python_type\n",
            "    return _json_schema_to_python_type(defs[schema[\"$ref\"].split(\"/\")[-1]], defs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 947, in _json_schema_to_python_type\n",
            "    des = [\n",
            "          ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 948, in <listcomp>\n",
            "    f\"{n}: {_json_schema_to_python_type(v, defs)}{get_desc(v)}\"\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 955, in _json_schema_to_python_type\n",
            "    f\"str, {_json_schema_to_python_type(schema['additionalProperties'], defs)}\"\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 901, in _json_schema_to_python_type\n",
            "    type_ = get_type(schema)\n",
            "            ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 863, in get_type\n",
            "    if \"const\" in schema:\n",
            "       ^^^^^^^^^^^^^^^^^\n",
            "TypeError: argument of type 'bool' is not iterable\n",
            "\u001b[31mERROR\u001b[0m:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 761, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 714, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 734, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 288, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 76, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 73, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 301, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 214, in run_endpoint_function\n",
            "    return await run_in_threadpool(dependant.call, **values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/concurrency.py\", line 37, in run_in_threadpool\n",
            "    return await anyio.to_thread.run_sync(func)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 431, in main\n",
            "    gradio_api_info = api_info(False)\n",
            "                      ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 460, in api_info\n",
            "    app.api_info = app.get_blocks().get_api_info()\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2785, in get_api_info\n",
            "    python_type = client_utils.json_schema_to_python_type(info)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 893, in json_schema_to_python_type\n",
            "    type_ = _json_schema_to_python_type(schema, schema.get(\"$defs\"))\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 938, in _json_schema_to_python_type\n",
            "    elements = _json_schema_to_python_type(items, defs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 908, in _json_schema_to_python_type\n",
            "    return _json_schema_to_python_type(defs[schema[\"$ref\"].split(\"/\")[-1]], defs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 947, in _json_schema_to_python_type\n",
            "    des = [\n",
            "          ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 948, in <listcomp>\n",
            "    f\"{n}: {_json_schema_to_python_type(v, defs)}{get_desc(v)}\"\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 955, in _json_schema_to_python_type\n",
            "    f\"str, {_json_schema_to_python_type(schema['additionalProperties'], defs)}\"\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 901, in _json_schema_to_python_type\n",
            "    type_ = get_type(schema)\n",
            "            ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 863, in get_type\n",
            "    if \"const\" in schema:\n",
            "       ^^^^^^^^^^^^^^^^^\n",
            "TypeError: argument of type 'bool' is not iterable\n",
            "\u001b[31mERROR\u001b[0m:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 761, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 714, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 734, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 288, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 76, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 73, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 301, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 214, in run_endpoint_function\n",
            "    return await run_in_threadpool(dependant.call, **values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/concurrency.py\", line 37, in run_in_threadpool\n",
            "    return await anyio.to_thread.run_sync(func)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 431, in main\n",
            "    gradio_api_info = api_info(False)\n",
            "                      ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 460, in api_info\n",
            "    app.api_info = app.get_blocks().get_api_info()\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2785, in get_api_info\n",
            "    python_type = client_utils.json_schema_to_python_type(info)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 893, in json_schema_to_python_type\n",
            "    type_ = _json_schema_to_python_type(schema, schema.get(\"$defs\"))\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 938, in _json_schema_to_python_type\n",
            "    elements = _json_schema_to_python_type(items, defs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 908, in _json_schema_to_python_type\n",
            "    return _json_schema_to_python_type(defs[schema[\"$ref\"].split(\"/\")[-1]], defs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 947, in _json_schema_to_python_type\n",
            "    des = [\n",
            "          ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 948, in <listcomp>\n",
            "    f\"{n}: {_json_schema_to_python_type(v, defs)}{get_desc(v)}\"\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 955, in _json_schema_to_python_type\n",
            "    f\"str, {_json_schema_to_python_type(schema['additionalProperties'], defs)}\"\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 901, in _json_schema_to_python_type\n",
            "    type_ = get_type(schema)\n",
            "            ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 863, in get_type\n",
            "    if \"const\" in schema:\n",
            "       ^^^^^^^^^^^^^^^^^\n",
            "TypeError: argument of type 'bool' is not iterable\n",
            "\u001b[31mERROR\u001b[0m:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 761, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 714, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 734, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 288, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 76, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 73, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 301, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 214, in run_endpoint_function\n",
            "    return await run_in_threadpool(dependant.call, **values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/concurrency.py\", line 37, in run_in_threadpool\n",
            "    return await anyio.to_thread.run_sync(func)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 431, in main\n",
            "    gradio_api_info = api_info(False)\n",
            "                      ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 460, in api_info\n",
            "    app.api_info = app.get_blocks().get_api_info()\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2785, in get_api_info\n",
            "    python_type = client_utils.json_schema_to_python_type(info)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 893, in json_schema_to_python_type\n",
            "    type_ = _json_schema_to_python_type(schema, schema.get(\"$defs\"))\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 938, in _json_schema_to_python_type\n",
            "    elements = _json_schema_to_python_type(items, defs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 908, in _json_schema_to_python_type\n",
            "    return _json_schema_to_python_type(defs[schema[\"$ref\"].split(\"/\")[-1]], defs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 947, in _json_schema_to_python_type\n",
            "    des = [\n",
            "          ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 948, in <listcomp>\n",
            "    f\"{n}: {_json_schema_to_python_type(v, defs)}{get_desc(v)}\"\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 955, in _json_schema_to_python_type\n",
            "    f\"str, {_json_schema_to_python_type(schema['additionalProperties'], defs)}\"\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 901, in _json_schema_to_python_type\n",
            "    type_ = get_type(schema)\n",
            "            ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 863, in get_type\n",
            "    if \"const\" in schema:\n",
            "       ^^^^^^^^^^^^^^^^^\n",
            "TypeError: argument of type 'bool' is not iterable\n",
            "\u001b[31mERROR\u001b[0m:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/applications.py\", line 112, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 761, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 714, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 734, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 288, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 76, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 73, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 301, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fastapi/routing.py\", line 214, in run_endpoint_function\n",
            "    return await run_in_threadpool(dependant.call, **values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/concurrency.py\", line 37, in run_in_threadpool\n",
            "    return await anyio.to_thread.run_sync(func)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 431, in main\n",
            "    gradio_api_info = api_info(False)\n",
            "                      ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/routes.py\", line 460, in api_info\n",
            "    app.api_info = app.get_blocks().get_api_info()\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2785, in get_api_info\n",
            "    python_type = client_utils.json_schema_to_python_type(info)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 893, in json_schema_to_python_type\n",
            "    type_ = _json_schema_to_python_type(schema, schema.get(\"$defs\"))\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 938, in _json_schema_to_python_type\n",
            "    elements = _json_schema_to_python_type(items, defs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 908, in _json_schema_to_python_type\n",
            "    return _json_schema_to_python_type(defs[schema[\"$ref\"].split(\"/\")[-1]], defs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 947, in _json_schema_to_python_type\n",
            "    des = [\n",
            "          ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 948, in <listcomp>\n",
            "    f\"{n}: {_json_schema_to_python_type(v, defs)}{get_desc(v)}\"\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 955, in _json_schema_to_python_type\n",
            "    f\"str, {_json_schema_to_python_type(schema['additionalProperties'], defs)}\"\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 901, in _json_schema_to_python_type\n",
            "    type_ = get_type(schema)\n",
            "            ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 863, in get_type\n",
            "    if \"const\" in schema:\n",
            "       ^^^^^^^^^^^^^^^^^\n",
            "TypeError: argument of type 'bool' is not iterable\n",
            "Running on public URL: https://605c5b349d7f509851.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2709, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fluxgym-Colab/app.py\", line 651, in <module>\n",
            "    demo.launch(show_error=True, allowed_paths=[cwd], share=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2614, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2713, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\", line 68, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://605c5b349d7f509851.gradio.live\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python app.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Clear any problematic environment variables\n",
        "if 'GRADIO_SHARE' in os.environ:\n",
        "    del os.environ['GRADIO_SHARE']\n",
        "if 'GRADIO_SERVER_NAME' in os.environ:\n",
        "    del os.environ['GRADIO_SERVER_NAME']"
      ],
      "metadata": {
        "id": "wtzFAjzReskS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the fluxgym directory\n",
        "!rm -rf fluxgym\n",
        "\n",
        "# Fresh clone\n",
        "!git clone https://github.com/cocktailpeanut/fluxgym\n",
        "%cd fluxgym\n",
        "!git clone -b sd3 https://github.com/kohya-ss/sd-scripts\n",
        "\n",
        "# Install requirements\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Start with minimal parameters\n",
        "!python app.py --share"
      ],
      "metadata": {
        "id": "WzXuvLmAe3nh",
        "outputId": "7316b87d-4c83-48d2-8285-c557787edc78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fluxgym'...\n",
            "remote: Enumerating objects: 297, done.\u001b[K\n",
            "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 297 (delta 154), reused 145 (delta 145), pack-reused 110 (from 2)\u001b[K\n",
            "Receiving objects: 100% (297/297), 16.52 MiB | 41.17 MiB/s, done.\n",
            "Resolving deltas: 100% (172/172), done.\n",
            "/content/fluxgym-Colab/fluxgym\n",
            "Cloning into 'sd-scripts'...\n",
            "remote: Enumerating objects: 9659, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 9659 (delta 15), reused 5 (delta 5), pack-reused 9634 (from 2)\u001b[K\n",
            "Receiving objects: 100% (9659/9659), 11.62 MiB | 22.58 MiB/s, done.\n",
            "Resolving deltas: 100% (6933/6933), done.\n",
            "Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements.txt (line 2))\n",
            "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-wn2eisoo\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-wn2eisoo\n",
            "  Resolved https://github.com/huggingface/diffusers.git to commit 0874dd04dc1bb359053935109dc95483218b086f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio_logsview@ https://huggingface.co/spaces/cocktailpeanut/gradio_logsview/resolve/main/gradio_logsview-0.0.17-py3-none-any.whl (from -r requirements.txt (line 3))\n",
            "  Using cached https://huggingface.co/spaces/cocktailpeanut/gradio_logsview/resolve/main/gradio_logsview-0.0.17-py3-none-any.whl (324 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (0.4.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.44.0)\n",
            "Requirement already satisfied: lycoris-lora==1.8.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.8.3)\n",
            "Requirement already satisfied: flatten_json in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.1.14)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: oyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.18.0)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.8.1)\n",
            "Requirement already satisfied: invisible-watermark in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.33.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.10.2)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.0.8)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.11.7)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (2.3.0)\n",
            "Requirement already satisfied: k-diffusion in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (0.1.1.post1)\n",
            "Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (2.32.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (1.0.15)\n",
            "Requirement already satisfied: prodigyopt in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (1.1.2)\n",
            "Requirement already satisfied: controlnet_aux==0.0.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (0.0.7)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (1.1.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (0.44.0)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (0.1.9)\n",
            "Requirement already satisfied: lpips in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (0.1.4)\n",
            "Requirement already satisfied: pytorch_fid in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (0.3.0)\n",
            "Requirement already satisfied: optimum-quanto in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.2.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (0.2.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (0.33.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (0.15.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (4.44.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (8.0.4)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (1.4.1)\n",
            "Collecting pydantic (from -r requirements.txt (line 16))\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from lycoris-lora==1.8.3->-r requirements.txt (line 5)) (2.6.0+cu124)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 16)) (0.7.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic->-r requirements.txt (line 16))\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 16)) (4.14.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (8.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (1.15.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (4.8.1.78)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (3.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (10.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 22)) (0.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.34.0.dev0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 4)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from flatten_json->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.1.3)\n",
            "Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.11/dist-packages (from kornia->-r requirements.txt (line 10)) (0.1.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from invisible-watermark->-r requirements.txt (line 11)) (1.8.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 13)) (5.9.5)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations->-r requirements.txt (line 15)) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->-r requirements.txt (line 15)) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->-r requirements.txt (line 15)) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->-r requirements.txt (line 15)) (6.4.9)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 17)) (4.9.3)\n",
            "Requirement already satisfied: clean-fid in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r requirements.txt (line 18)) (0.1.35)\n",
            "Requirement already satisfied: clip-anytorch in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r requirements.txt (line 18)) (2.6.0)\n",
            "Requirement already satisfied: dctorch in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r requirements.txt (line 18)) (0.1.2)\n",
            "Requirement already satisfied: jsonmerge in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r requirements.txt (line 18)) (1.9.2)\n",
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r requirements.txt (line 18)) (0.2.5)\n",
            "Requirement already satisfied: torchsde in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r requirements.txt (line 18)) (0.2.6)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from k-diffusion->-r requirements.txt (line 18)) (0.20.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from open_clip_torch->-r requirements.txt (line 19)) (6.1.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from optimum-quanto->-r requirements.txt (line 28)) (1.11.1.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r requirements.txt (line 30)) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->-r requirements.txt (line 30)) (1.1.3)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (2.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.11.13)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.16.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (2.4.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 32)) (0.34.3)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.3.0->gradio->-r requirements.txt (line 32)) (12.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->-r requirements.txt (line 33)) (1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 32)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 32)) (1.3.1)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1.0->gradio->-r requirements.txt (line 32)) (0.46.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 32)) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 32)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 32)) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 32)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 32)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 32)) (2025.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->lycoris-lora==1.8.3->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (13.7.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch->-r requirements.txt (line 19)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->controlnet_aux==0.0.7->-r requirements.txt (line 22)) (3.23.0)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.11/dist-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 18)) (4.24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.34.0.dev0->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->controlnet_aux==0.0.7->-r requirements.txt (line 22)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->controlnet_aux==0.0.7->-r requirements.txt (line 22)) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->controlnet_aux==0.0.7->-r requirements.txt (line 22)) (0.4)\n",
            "Requirement already satisfied: trampoline>=0.1.2 in /usr/local/lib/python3.11/dist-packages (from torchsde->k-diffusion->-r requirements.txt (line 18)) (0.1.2)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 18)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 18)) (4.3.8)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 18)) (2.30.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 18)) (1.3.6)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 18)) (4.0.12)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 18)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 18)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 18)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 18)) (0.25.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (2.19.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 18)) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 32)) (0.1.2)\n",
            "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydantic-core, pydantic\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-genai 1.20.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pydantic-2.9.2 pydantic-core-2.23.4\n",
            "2025-06-20 22:35:56.186077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750458956.222614    6941 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750458956.234253    6941 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-20 22:35:56.269707: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/import_utils.py\", line 883, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders/single_file.py\", line 25, in <module>\n",
            "    from .single_file_utils import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders/single_file_utils.py\", line 28, in <module>\n",
            "    from ..models.modeling_utils import load_state_dict\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py\", line 40, in <module>\n",
            "    from ..quantizers import DiffusersAutoQuantizer, DiffusersQuantizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/quantizers/__init__.py\", line 19, in <module>\n",
            "    from .auto import DiffusersAutoQuantizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/quantizers/auto.py\", line 22, in <module>\n",
            "    from .bitsandbytes import BnB4BitDiffusersQuantizer, BnB8BitDiffusersQuantizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/quantizers/bitsandbytes/__init__.py\", line 2, in <module>\n",
            "    from .utils import dequantize_and_replace, dequantize_bnb_weight, replace_with_bnb_linear\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/quantizers/bitsandbytes/utils.py\", line 32, in <module>\n",
            "    import bitsandbytes as bnb\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/__init__.py\", line 15, in <module>\n",
            "    from .nn import modules\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/__init__.py\", line 21, in <module>\n",
            "    from .triton_based_modules import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/triton_based_modules.py\", line 7, in <module>\n",
            "    from bitsandbytes.triton.int8_matmul_mixed_dequantize import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/triton/int8_matmul_mixed_dequantize.py\", line 12, in <module>\n",
            "    from triton.ops.matmul_perf_model import early_config_prune, estimate_matmul_time\n",
            "ModuleNotFoundError: No module named 'triton.ops'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/import_utils.py\", line 883, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 24, in <module>\n",
            "    from ...loaders import FromSingleFileMixin, IPAdapterMixin, StableDiffusionLoraLoaderMixin, TextualInversionLoaderMixin\n",
            "  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/import_utils.py\", line 873, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/import_utils.py\", line 885, in _get_module\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Failed to import diffusers.loaders.single_file because of the following error (look up to see its traceback):\n",
            "No module named 'triton.ops'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fluxgym-Colab/fluxgym/app.py\", line 19, in <module>\n",
            "    from library import flux_train_utils, huggingface_util\n",
            "  File \"/content/fluxgym-Colab/sd-scripts/library/flux_train_utils.py\", line 17, in <module>\n",
            "    from library import flux_models, flux_utils, strategy_base, train_util\n",
            "  File \"/content/fluxgym-Colab/sd-scripts/library/train_util.py\", line 48, in <module>\n",
            "    from diffusers import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/import_utils.py\", line 874, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/import_utils.py\", line 874, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/import_utils.py\", line 873, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/diffusers/utils/import_utils.py\", line 885, in _get_module\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Failed to import diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion because of the following error (look up to see its traceback):\n",
            "Failed to import diffusers.loaders.single_file because of the following error (look up to see its traceback):\n",
            "No module named 'triton.ops'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, fix the triton issue\n",
        "!pip uninstall -y triton\n",
        "!pip install triton\n",
        "\n",
        "# If that doesn't work, try the specific version:\n",
        "!pip install triton==2.3.1\n",
        "\n",
        "# Then reinstall diffusers with compatible version\n",
        "!pip install diffusers==0.30.3\n",
        "\n",
        "# Restart runtime after this"
      ],
      "metadata": {
        "id": "cwHSiCttfMgw",
        "outputId": "46985e73-e34c-4cde-d8cb-9dda50f59848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: triton 3.2.0\n",
            "Uninstalling triton-3.2.0:\n",
            "  Successfully uninstalled triton-3.2.0\n",
            "Collecting triton\n",
            "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton) (75.2.0)\n",
            "Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires triton==3.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have triton 3.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed triton-3.3.1\n",
            "Collecting triton==2.3.1\n",
            "  Downloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton==2.3.1) (3.18.0)\n",
            "Downloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.3.1\n",
            "    Uninstalling triton-3.3.1:\n",
            "      Successfully uninstalled triton-3.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires triton==3.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have triton 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed triton-2.3.1\n",
            "Collecting diffusers==0.30.3\n",
            "  Downloading diffusers-0.30.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.30.3) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.30.3) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.30.3) (0.33.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.30.3) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.30.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.30.3) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.30.3) (0.4.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.30.3) (10.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.3) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.3) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.3) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.3) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.30.3) (1.1.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.30.3) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.30.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.30.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.30.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.30.3) (2025.6.15)\n",
            "Downloading diffusers-0.30.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.34.0.dev0\n",
            "    Uninstalling diffusers-0.34.0.dev0:\n",
            "      Successfully uninstalled diffusers-0.34.0.dev0\n",
            "Successfully installed diffusers-0.30.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/fluxgym-Colab"
      ],
      "metadata": {
        "id": "vHoQCY0yfmoe",
        "outputId": "705700db-1bb3-464f-b443-b2d206d004fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py --share --listen 0.0.0.0 --port 7860"
      ],
      "metadata": {
        "id": "bw4kVj65foQi",
        "outputId": "b8720ee2-9c94-421d-9fc4-642d937f3bb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-20 23:00:33.249575: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750460433.271080   13465 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750460433.277699   13465 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-20 23:00:33.299735: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://d5b76ad5958d846475.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "launched\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3r, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3r, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rry, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rry, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rryN, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rryN, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rryN30, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rryN30n, sample_every_n_steps=0\n",
            "max_train_epochs=16 num_images=16, num_repeats=10, total_steps=2560\n",
            "run_captioning\n",
            "concept sentence K3rryN30n\n",
            "captions ('K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '')\n",
            "device=cuda\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.6108, -0.5938, -0.5596,  ...,  0.1426,  0.1426,  0.1426],\n",
            "          [-0.5938, -0.5938, -0.5596,  ...,  0.1426,  0.1426,  0.1426],\n",
            "          [-0.5767, -0.5767, -0.5425,  ...,  0.1426,  0.1426,  0.1426],\n",
            "          ...,\n",
            "          [-0.1656, -0.0801, -0.0458,  ..., -0.8164, -0.8506, -0.8506],\n",
            "          [-0.1315, -0.0629, -0.0287,  ..., -0.8506, -0.8506, -0.8677],\n",
            "          [-0.1315, -0.0629, -0.0458,  ..., -0.8506, -0.8677, -0.8848]],\n",
            "\n",
            "         [[-0.5479, -0.5303, -0.4951,  ...,  0.3276,  0.3276,  0.3276],\n",
            "          [-0.5303, -0.5303, -0.4951,  ...,  0.3276,  0.3276,  0.3276],\n",
            "          [-0.5127, -0.5127, -0.4775,  ...,  0.3276,  0.3276,  0.3276],\n",
            "          ...,\n",
            "          [ 0.3977,  0.4854,  0.5205,  ..., -0.5127, -0.5479, -0.5479],\n",
            "          [ 0.4329,  0.5029,  0.5376,  ..., -0.5479, -0.5479, -0.5649],\n",
            "          [ 0.4329,  0.5029,  0.5205,  ..., -0.5479, -0.5649, -0.5825]],\n",
            "\n",
            "         [[-0.6543, -0.6367, -0.6021,  ...,  0.2173,  0.2173,  0.2173],\n",
            "          [-0.6367, -0.6367, -0.6021,  ...,  0.2173,  0.2173,  0.2173],\n",
            "          [-0.6191, -0.6191, -0.5845,  ...,  0.2173,  0.2173,  0.2173],\n",
            "          ...,\n",
            "          [ 0.7402,  0.8271,  0.8623,  ..., -0.2532, -0.2881, -0.2881],\n",
            "          [ 0.7749,  0.8447,  0.8799,  ..., -0.2881, -0.2881, -0.3054],\n",
            "          [ 0.7749,  0.8447,  0.8623,  ..., -0.2881, -0.3054, -0.3230]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,  2828,    15,    10,\n",
            "         16433,    19,    69,  5856,  7344,     6,  2498,    10,  6907, 28072,\n",
            "          2459,  6439,     4,   264,    16,  7501,    30, 31601,  2485,     8,\n",
            "            89,    16,    10,  2204,    11,     5,  3618,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman sitting on a couch with her legs crossed, wearing a pink bodysuit. She is surrounded by cushions and there is a wall in the background.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman sitting on a couch with her legs crossed, wearing a pink bodysuit. She is surrounded by cushions and there is a wall in the background.'}\n",
            "caption_text = a woman sitting on a couch with her legs crossed, wearing a pink bodysuit. She is surrounded by cushions and there is a wall in the background., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[1.7178, 1.7178, 1.7178,  ..., 1.6328, 1.6328, 1.6328],\n",
            "          [1.7178, 1.7178, 1.7178,  ..., 1.6328, 1.6328, 1.6328],\n",
            "          [1.7178, 1.7178, 1.7178,  ..., 1.6328, 1.6328, 1.6328],\n",
            "          ...,\n",
            "          [1.6494, 1.6494, 1.6494,  ..., 1.2900, 1.2900, 1.2900],\n",
            "          [1.6494, 1.6494, 1.6494,  ..., 1.2900, 1.2900, 1.2900],\n",
            "          [1.6494, 1.6494, 1.6494,  ..., 1.2900, 1.2900, 1.2900]],\n",
            "\n",
            "         [[1.8857, 1.8857, 1.8857,  ..., 1.9033, 1.9033, 1.9033],\n",
            "          [1.8857, 1.8857, 1.8857,  ..., 1.9033, 1.9033, 1.9033],\n",
            "          [1.8857, 1.8857, 1.8857,  ..., 1.9033, 1.9033, 1.9033],\n",
            "          ...,\n",
            "          [1.9209, 1.9209, 1.9209,  ..., 1.4658, 1.4658, 1.4658],\n",
            "          [1.9209, 1.9209, 1.9209,  ..., 1.4658, 1.4658, 1.4658],\n",
            "          [1.9209, 1.9209, 1.9209,  ..., 1.4658, 1.4658, 1.4658]],\n",
            "\n",
            "         [[2.0996, 2.0996, 2.0996,  ..., 2.1172, 2.1172, 2.1172],\n",
            "          [2.0996, 2.0996, 2.0996,  ..., 2.1172, 2.1172, 2.1172],\n",
            "          [2.0996, 2.0996, 2.0996,  ..., 2.1172, 2.1172, 2.1172],\n",
            "          ...,\n",
            "          [2.1348, 2.1348, 2.1348,  ..., 1.5947, 1.5947, 1.5947],\n",
            "          [2.1348, 2.1348, 2.1348,  ..., 1.5947, 1.5947, 1.5947],\n",
            "          [2.1348, 2.1348, 2.1348,  ..., 1.5947, 1.5947, 1.5947]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    11,    10,   909,\n",
            "          3235, 12681,    13,    10,  2170,   136,    10,  1104,  3618,     4,\n",
            "           264,    16,  2498,    10,   909,  3089, 14609,     6,  1311,    69,\n",
            "            10, 10364,     8, 14160,   356,     4,  1405,  2549,    16, 25845,\n",
            "            11,    10, 19474,     8, 10364,  4737,     6,     8,    69,  7855,\n",
            "            16, 12405,   648, 18842,     4,   264,  1326,  3230,     8, 10137,\n",
            "             6,  1227,     7,   185,    15,     5,   232,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman in a black suit posing for a picture against a white background. She is wearing a black blazer, giving her a sophisticated and stylish look. Her hair is styled in a sleek and sophisticated manner, and her makeup is subtle yet glamorous. She looks confident and poised, ready to take on the world.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman in a black suit posing for a picture against a white background. She is wearing a black blazer, giving her a sophisticated and stylish look. Her hair is styled in a sleek and sophisticated manner, and her makeup is subtle yet glamorous. She looks confident and poised, ready to take on the world.'}\n",
            "caption_text = a woman in a black suit posing for a picture against a white background. She is wearing a black blazer, giving her a sophisticated and stylish look. Her hair is styled in a sleek and sophisticated manner, and her makeup is subtle yet glamorous. She looks confident and poised, ready to take on the world., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.5254, -0.5254, -0.5083,  ..., -1.4844, -1.4844, -1.4844],\n",
            "          [-0.5254, -0.5254, -0.5083,  ..., -1.4844, -1.4844, -1.4844],\n",
            "          [-0.5083, -0.5083, -0.4910,  ..., -1.4844, -1.4844, -1.4844],\n",
            "          ...,\n",
            "          [-1.9639, -1.9463, -1.9297,  ..., -1.7754, -1.7754, -1.7578],\n",
            "          [-1.9639, -1.9463, -1.9297,  ..., -1.8096, -1.7930, -1.7754],\n",
            "          [-1.9639, -1.9463, -1.9297,  ..., -1.8096, -1.8096, -1.7754]],\n",
            "\n",
            "         [[-0.3726, -0.3726, -0.3550,  ..., -1.3525, -1.3525, -1.3525],\n",
            "          [-0.3726, -0.3726, -0.3550,  ..., -1.3525, -1.3525, -1.3525],\n",
            "          [-0.3550, -0.3550, -0.3376,  ..., -1.3525, -1.3525, -1.3525],\n",
            "          ...,\n",
            "          [-1.8086, -1.7910, -1.7734,  ..., -1.5801, -1.5977, -1.5977],\n",
            "          [-1.8086, -1.7910, -1.7734,  ..., -1.6152, -1.6152, -1.6152],\n",
            "          [-1.8086, -1.7910, -1.7734,  ..., -1.6152, -1.6328, -1.6152]],\n",
            "\n",
            "         [[-0.3926, -0.3926, -0.3752,  ..., -1.3691, -1.3691, -1.3691],\n",
            "          [-0.3926, -0.3926, -0.3752,  ..., -1.3691, -1.3691, -1.3691],\n",
            "          [-0.3752, -0.3752, -0.3579,  ..., -1.3691, -1.3691, -1.3691],\n",
            "          ...,\n",
            "          [-1.5605, -1.5430, -1.5254,  ..., -1.3857, -1.3857, -1.3857],\n",
            "          [-1.5605, -1.5430, -1.5254,  ..., -1.4209, -1.4209, -1.4033],\n",
            "          [-1.5605, -1.5430, -1.5254,  ..., -1.4209, -1.4209, -1.4033]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    11,    10,  6907,\n",
            "          3588,  2828,    15,    10, 16433,     6,    19,    10,  2204,    11,\n",
            "             5,  3618,     4,   264,    16,  2498,  7855,     6,    61,    16,\n",
            "            65,     9,     5,   158,   275,  7855,  1326,    13,   358,  3024,\n",
            "          6328,     4,  1405,  2473,    32,  6263,    19,    10, 12405,  5278,\n",
            "         24878,  2295,   356,     6,    69, 14638,    32, 10122,    10, 29282,\n",
            "          6907,     6,     8,    69, 32040,    32,  8541,  8855,    19,    10,\n",
            "          1109,  6907, 33556,     4,  1405,  2549,    16, 25845,    11,  7082,\n",
            "          6995,     6,     8,    79,    16,  2498,  9865,  7855,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman in a pink dress sitting on a couch, with a wall in the background. She is wearing makeup, which is one of the 10 best makeup looks for every skin tone. Her eyes are highlighted with a subtle smoky eye look, her lips are painted a glossy pink, and her cheeks are contoured with a light pink blush. Her hair is styled in loose waves, and she is wearing minimal makeup.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman in a pink dress sitting on a couch, with a wall in the background. She is wearing makeup, which is one of the 10 best makeup looks for every skin tone. Her eyes are highlighted with a subtle smoky eye look, her lips are painted a glossy pink, and her cheeks are contoured with a light pink blush. Her hair is styled in loose waves, and she is wearing minimal makeup.'}\n",
            "caption_text = a woman in a pink dress sitting on a couch, with a wall in the background. She is wearing makeup, which is one of the 10 best makeup looks for every skin tone. Her eyes are highlighted with a subtle smoky eye look, her lips are painted a glossy pink, and her cheeks are contoured with a light pink blush. Her hair is styled in loose waves, and she is wearing minimal makeup., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.3711, -0.3711, -0.3711,  ..., -0.0629, -0.0287, -0.0287],\n",
            "          [-0.3711, -0.3711, -0.3711,  ..., -0.0629, -0.0287, -0.0287],\n",
            "          [-0.3711, -0.3711, -0.3711,  ..., -0.0629, -0.0287, -0.0287],\n",
            "          ...,\n",
            "          [ 0.9302,  0.9302,  0.9473,  ...,  0.1255,  0.1940,  0.2625],\n",
            "          [ 0.9814,  0.9814,  0.9473,  ...,  0.0912,  0.1940,  0.2625],\n",
            "          [ 1.0156,  1.0156,  0.9814,  ...,  0.1426,  0.1597,  0.1940]],\n",
            "\n",
            "         [[-0.3726, -0.3726, -0.3726,  ...,  0.0476,  0.0826,  0.0826],\n",
            "          [-0.3726, -0.3726, -0.3726,  ...,  0.0476,  0.0826,  0.0826],\n",
            "          [-0.3726, -0.3726, -0.3726,  ...,  0.0476,  0.0826,  0.0826],\n",
            "          ...,\n",
            "          [ 1.0977,  1.0977,  1.1152,  ...,  0.2227,  0.2927,  0.3628],\n",
            "          [ 1.1504,  1.1504,  1.1152,  ...,  0.1876,  0.2927,  0.3628],\n",
            "          [ 1.1855,  1.1855,  1.1504,  ...,  0.2402,  0.2578,  0.2927]],\n",
            "\n",
            "         [[-0.4624, -0.4624, -0.4624,  ..., -0.0790, -0.0441, -0.0441],\n",
            "          [-0.4624, -0.4624, -0.4624,  ..., -0.0790, -0.0441, -0.0441],\n",
            "          [-0.4624, -0.4624, -0.4624,  ..., -0.0790, -0.0441, -0.0441],\n",
            "          ...,\n",
            "          [ 1.2109,  1.2109,  1.2285,  ...,  0.2173,  0.2871,  0.3567],\n",
            "          [ 1.2627,  1.2627,  1.2285,  ...,  0.1825,  0.2871,  0.3567],\n",
            "          [ 1.2979,  1.2979,  1.2627,  ...,  0.2347,  0.2522,  0.2871]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,  2934,    11,    10,\n",
            "         22097,    19,    69,  1420,    15,    69, 28097,     6,  2498,    10,\n",
            "          6907,  6013,   299,     8, 10844,     4,    20,  3618,    16,  2829,\n",
            "         34186,     6,     8,    89,    16,    10,   909,  7626,    11,     5,\n",
            "          3618,     4,     2]], device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman standing in a hallway with her hands on her hips, wearing a pink tank top and jeans. The background is slightly blurred, and there is a black object in the background.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman standing in a hallway with her hands on her hips, wearing a pink tank top and jeans. The background is slightly blurred, and there is a black object in the background.'}\n",
            "caption_text = a woman standing in a hallway with her hands on her hips, wearing a pink tank top and jeans. The background is slightly blurred, and there is a black object in the background., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[1.1533, 1.1533, 1.1533,  ..., 0.7935, 0.7935, 0.7935],\n",
            "          [1.1533, 1.1533, 1.1533,  ..., 0.7935, 0.7935, 0.7935],\n",
            "          [1.1699, 1.1699, 1.1699,  ..., 0.8105, 0.8105, 0.8105],\n",
            "          ...,\n",
            "          [1.1191, 1.1191, 1.1191,  ..., 0.8276, 0.8276, 0.8276],\n",
            "          [1.1191, 1.1191, 1.1191,  ..., 0.8276, 0.8276, 0.8276],\n",
            "          [1.1191, 1.1191, 1.1191,  ..., 0.8276, 0.8276, 0.8276]],\n",
            "\n",
            "         [[1.3428, 1.3428, 1.3428,  ..., 0.9756, 0.9756, 0.9756],\n",
            "          [1.3428, 1.3428, 1.3428,  ..., 0.9756, 0.9756, 0.9756],\n",
            "          [1.3604, 1.3604, 1.3604,  ..., 0.9932, 0.9932, 0.9932],\n",
            "          ...,\n",
            "          [1.4131, 1.4131, 1.4131,  ..., 1.0459, 1.0459, 1.0459],\n",
            "          [1.4131, 1.4131, 1.4131,  ..., 1.0459, 1.0459, 1.0459],\n",
            "          [1.4131, 1.4131, 1.4131,  ..., 1.0459, 1.0459, 1.0459]],\n",
            "\n",
            "         [[1.3330, 1.3330, 1.3330,  ..., 0.9492, 0.9492, 0.9492],\n",
            "          [1.3330, 1.3330, 1.3330,  ..., 0.9492, 0.9492, 0.9492],\n",
            "          [1.3506, 1.3506, 1.3506,  ..., 0.9668, 0.9668, 0.9668],\n",
            "          ...,\n",
            "          [1.6641, 1.6641, 1.6641,  ..., 1.2803, 1.2803, 1.2803],\n",
            "          [1.6641, 1.6641, 1.6641,  ..., 1.2803, 1.2803, 1.2803],\n",
            "          [1.6641, 1.6641, 1.6641,  ..., 1.2803, 1.2803, 1.2803]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    19,   251,  6219,\n",
            "          2549,  2498,    10,  6907,  3588,     6,  2934,    11,   760,     9,\n",
            "            10,  2204,     4,   264,    34,    10,  3230,  6663,     8,    69,\n",
            "          2549,    16, 25845,    11,    10,   169,    14, 16420,    69,   652,\n",
            "             4,  1405,  3588,    16,    10,  1109,  6907,  3195,     8,    34,\n",
            "            10, 15500,  5397,  1902,     4,    20,  2204,   639,    69,    16,\n",
            "            10,  7974,  3195,     8,    16, 10122,    10,  1109, 13686,     9,\n",
            "          6907,     4,     2]], device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair wearing a pink dress, standing in front of a wall. She has a confident stance and her hair is styled in a way that frames her face. Her dress is a light pink color and has a scoop neckline. The wall behind her is a neutral color and is painted a light shade of pink.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair wearing a pink dress, standing in front of a wall. She has a confident stance and her hair is styled in a way that frames her face. Her dress is a light pink color and has a scoop neckline. The wall behind her is a neutral color and is painted a light shade of pink.'}\n",
            "caption_text = a woman with long brown hair wearing a pink dress, standing in front of a wall. She has a confident stance and her hair is styled in a way that frames her face. Her dress is a light pink color and has a scoop neckline. The wall behind her is a neutral color and is painted a light shade of pink., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[ 0.3137,  0.3137,  0.3137,  ...,  0.1940,  0.1940,  0.1940],\n",
            "          [ 0.3137,  0.3137,  0.3137,  ...,  0.1940,  0.1940,  0.1940],\n",
            "          [ 0.3137,  0.3137,  0.3137,  ...,  0.1940,  0.1940,  0.1940],\n",
            "          ...,\n",
            "          [-0.0116,  0.0056,  0.0398,  ..., -0.1486, -0.1486, -0.1486],\n",
            "          [-0.0116,  0.0056,  0.0398,  ..., -0.1486, -0.1486, -0.1486],\n",
            "          [-0.0116,  0.0056,  0.0398,  ..., -0.1486, -0.1486, -0.1486]],\n",
            "\n",
            "         [[ 0.4678,  0.4678,  0.4678,  ...,  0.3103,  0.3103,  0.3103],\n",
            "          [ 0.4678,  0.4678,  0.4678,  ...,  0.3103,  0.3103,  0.3103],\n",
            "          [ 0.4678,  0.4678,  0.4678,  ...,  0.3103,  0.3103,  0.3103],\n",
            "          ...,\n",
            "          [ 0.3452,  0.3628,  0.3977,  ...,  0.0126,  0.0126,  0.0126],\n",
            "          [ 0.3452,  0.3628,  0.3977,  ...,  0.0126,  0.0126,  0.0126],\n",
            "          [ 0.3452,  0.3628,  0.3977,  ...,  0.0126,  0.0126,  0.0126]],\n",
            "\n",
            "         [[ 0.4092,  0.4092,  0.4092,  ...,  0.2173,  0.2173,  0.2173],\n",
            "          [ 0.4092,  0.4092,  0.4092,  ...,  0.2173,  0.2173,  0.2173],\n",
            "          [ 0.4092,  0.4092,  0.4092,  ...,  0.2173,  0.2173,  0.2173],\n",
            "          ...,\n",
            "          [ 0.6704,  0.6880,  0.7227,  ...,  0.0082,  0.0082,  0.0082],\n",
            "          [ 0.6704,  0.6880,  0.7227,  ...,  0.0082,  0.0082,  0.0082],\n",
            "          [ 0.6704,  0.6880,  0.7227,  ...,  0.0082,  0.0082,  0.0082]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    19,   251,  6219,\n",
            "          2549,  2498,    10,  6907, 11689,   299,     6,  2934,    11,   760,\n",
            "             9,    10,  2204,     4,   264,    34,    10,  3230,     8,  3030,\n",
            "          8151,    15,    69,   652,     6,     8,    69, 24210,    16,   670,\n",
            "             8,  2602,     4,  1405,  2549,    16, 25845,    11,    10,   169,\n",
            "            14, 16420,    69,   652,     8, 15056, 24597,    69,  1575,     4,\n",
            "            20,  2204,   639,    69,    16, 10798,     8,  1104,     6,  1976,\n",
            "            10,  7974, 11379,    13,    69,  7490,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair wearing a pink bra top, standing in front of a wall. She has a confident and determined expression on her face, and her posture is strong and proud. Her hair is styled in a way that frames her face and accentuates her features. The wall behind her is plain and white, providing a neutral backdrop for her outfit.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair wearing a pink bra top, standing in front of a wall. She has a confident and determined expression on her face, and her posture is strong and proud. Her hair is styled in a way that frames her face and accentuates her features. The wall behind her is plain and white, providing a neutral backdrop for her outfit.'}\n",
            "caption_text = a woman with long brown hair wearing a pink bra top, standing in front of a wall. She has a confident and determined expression on her face, and her posture is strong and proud. Her hair is styled in a way that frames her face and accentuates her features. The wall behind her is plain and white, providing a neutral backdrop for her outfit., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[ 0.2795,  0.2795,  0.2966,  ...,  0.2111,  0.1940,  0.1940],\n",
            "          [ 0.2795,  0.2795,  0.2966,  ...,  0.2111,  0.1940,  0.1940],\n",
            "          [ 0.2795,  0.2795,  0.2966,  ...,  0.2111,  0.1940,  0.1940],\n",
            "          ...,\n",
            "          [-0.4397, -0.4397, -0.4226,  ..., -0.3711, -0.3711, -0.3711],\n",
            "          [-0.4226, -0.4226, -0.4055,  ..., -0.3882, -0.3882, -0.3882],\n",
            "          [-0.4226, -0.4226, -0.4055,  ..., -0.3882, -0.3882, -0.3882]],\n",
            "\n",
            "         [[ 0.4329,  0.4329,  0.4502,  ...,  0.3276,  0.3103,  0.3103],\n",
            "          [ 0.4329,  0.4329,  0.4502,  ...,  0.3276,  0.3103,  0.3103],\n",
            "          [ 0.4329,  0.4329,  0.4502,  ...,  0.3276,  0.3103,  0.3103],\n",
            "          ...,\n",
            "          [-0.3025, -0.3025, -0.2849,  ..., -0.2849, -0.2849, -0.2849],\n",
            "          [-0.2849, -0.2849, -0.2676,  ..., -0.3025, -0.3025, -0.3025],\n",
            "          [-0.2849, -0.2849, -0.2676,  ..., -0.3025, -0.3025, -0.3025]],\n",
            "\n",
            "         [[ 0.3394,  0.3394,  0.3567,  ...,  0.2000,  0.1825,  0.1825],\n",
            "          [ 0.3394,  0.3394,  0.3567,  ...,  0.2000,  0.1825,  0.1825],\n",
            "          [ 0.3394,  0.3394,  0.3567,  ...,  0.2000,  0.1825,  0.1825],\n",
            "          ...,\n",
            "          [-0.1835, -0.1835, -0.1661,  ..., -0.3230, -0.3230, -0.3230],\n",
            "          [-0.1661, -0.1661, -0.1487,  ..., -0.3403, -0.3403, -0.3403],\n",
            "          [-0.1661, -0.1661, -0.1487,  ..., -0.3403, -0.3403, -0.3403]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    11,    10,  6907,\n",
            "          3588, 12382,    23,     5,  2280,   136,    10,  1104,  3618,     4,\n",
            "           264,    16,  2006,    25,  7103,   726,  3178,     6,     8,     5,\n",
            "          2274,    21,   551,    30,    10,  2038,  9463,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman in a pink dress smiling at the camera against a white background. She is identified as Jessica Alba, and the image was taken by a professional photographer.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman in a pink dress smiling at the camera against a white background. She is identified as Jessica Alba, and the image was taken by a professional photographer.'}\n",
            "caption_text = a woman in a pink dress smiling at the camera against a white background. She is identified as Jessica Alba, and the image was taken by a professional photographer., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.5254, -0.5254, -0.5254,  ..., -0.2856, -0.2856, -0.2856],\n",
            "          [-0.5254, -0.5254, -0.5254,  ..., -0.2856, -0.2856, -0.2856],\n",
            "          [-0.5254, -0.5254, -0.5254,  ..., -0.2683, -0.2683, -0.2683],\n",
            "          ...,\n",
            "          [ 0.8447,  0.8447,  0.8447,  ...,  0.0398,  0.0398,  0.0227],\n",
            "          [ 0.8447,  0.8447,  0.8447,  ...,  0.0740,  0.0569,  0.0398],\n",
            "          [ 0.8447,  0.8447,  0.8447,  ...,  0.0740,  0.0398,  0.0398]],\n",
            "\n",
            "         [[-0.4602, -0.4602, -0.4602,  ..., -0.2676, -0.2676, -0.2676],\n",
            "          [-0.4602, -0.4602, -0.4602,  ..., -0.2676, -0.2676, -0.2676],\n",
            "          [-0.4602, -0.4602, -0.4602,  ..., -0.2500, -0.2500, -0.2500],\n",
            "          ...,\n",
            "          [ 1.2559,  1.2559,  1.2559,  ...,  0.2052,  0.2052,  0.1876],\n",
            "          [ 1.2559,  1.2559,  1.2559,  ...,  0.2402,  0.2227,  0.2052],\n",
            "          [ 1.2559,  1.2559,  1.2559,  ...,  0.2402,  0.2052,  0.2052]],\n",
            "\n",
            "         [[-0.5322, -0.5322, -0.5322,  ..., -0.4275, -0.4275, -0.4275],\n",
            "          [-0.5322, -0.5322, -0.5322,  ..., -0.4275, -0.4275, -0.4275],\n",
            "          [-0.5322, -0.5322, -0.5322,  ..., -0.4102, -0.4102, -0.4102],\n",
            "          ...,\n",
            "          [ 1.5596,  1.5596,  1.5596,  ...,  0.3394,  0.3394,  0.3220],\n",
            "          [ 1.5596,  1.5596,  1.5596,  ...,  0.3743,  0.3567,  0.3394],\n",
            "          [ 1.5596,  1.5596,  1.5596,  ...,  0.3743,  0.3394,  0.3394]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,  3051,   159,    10,\n",
            "         22097,    11,    10,  6907,  6013,   299,     8, 10844,     6,    19,\n",
            "            10,   909,  7626,    15,     5,   314,   526,     9,     5,  2274,\n",
            "             8,    10,  2204,     8,  1883,    11,     5,  3618,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman walking down a hallway in a pink tank top and jeans, with a black object on the left side of the image and a wall and door in the background.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman walking down a hallway in a pink tank top and jeans, with a black object on the left side of the image and a wall and door in the background.'}\n",
            "caption_text = a woman walking down a hallway in a pink tank top and jeans, with a black object on the left side of the image and a wall and door in the background., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-2.0488, -2.0488, -2.0488,  ..., -2.0156, -2.0156, -2.0156],\n",
            "          [-2.0488, -2.0488, -2.0488,  ..., -2.0156, -2.0156, -2.0156],\n",
            "          [-2.0488, -2.0488, -2.0488,  ..., -2.0156, -2.0156, -2.0156],\n",
            "          ...,\n",
            "          [-2.0664, -2.0664, -2.0664,  ..., -1.9121, -1.9297, -1.9297],\n",
            "          [-2.0664, -2.0664, -2.0664,  ..., -1.9121, -1.9297, -1.9297],\n",
            "          [-2.0664, -2.0664, -2.0664,  ..., -1.9121, -1.9297, -1.9297]],\n",
            "\n",
            "         [[-1.9658, -1.9658, -1.9658,  ..., -1.8955, -1.8955, -1.8955],\n",
            "          [-1.9658, -1.9658, -1.9658,  ..., -1.8955, -1.8955, -1.8955],\n",
            "          [-1.9658, -1.9658, -1.9658,  ..., -1.8955, -1.8955, -1.8955],\n",
            "          ...,\n",
            "          [-1.9834, -1.9834, -1.9834,  ..., -1.8779, -1.8955, -1.8955],\n",
            "          [-1.9834, -1.9834, -1.9834,  ..., -1.8779, -1.8955, -1.8955],\n",
            "          [-1.9834, -1.9834, -1.9834,  ..., -1.8779, -1.8955, -1.8955]],\n",
            "\n",
            "         [[-1.7344, -1.7344, -1.7344,  ..., -1.6826, -1.6826, -1.6826],\n",
            "          [-1.7344, -1.7344, -1.7344,  ..., -1.6826, -1.6826, -1.6826],\n",
            "          [-1.7344, -1.7344, -1.7344,  ..., -1.6826, -1.6826, -1.6826],\n",
            "          ...,\n",
            "          [-1.7520, -1.7520, -1.7520,  ..., -1.7344, -1.7520, -1.7520],\n",
            "          [-1.7520, -1.7520, -1.7520,  ..., -1.7344, -1.7520, -1.7520],\n",
            "          [-1.7520, -1.7520, -1.7520,  ..., -1.7344, -1.7520, -1.7520]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[   2,    0,  133, 2274,  924,   10,  693,   19,  251, 6219, 2549,  546,\n",
            "         2024,   23,    5, 2280,  136,   10, 2933, 3618,    4,    2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair looking directly at the camera against a dark background.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair looking directly at the camera against a dark background.'}\n",
            "caption_text = a woman with long brown hair looking directly at the camera against a dark background., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[1.7861, 1.7861, 1.7861,  ..., 1.6670, 1.6670, 1.6670],\n",
            "          [1.7861, 1.7861, 1.7861,  ..., 1.6670, 1.6670, 1.6670],\n",
            "          [1.7861, 1.7861, 1.7861,  ..., 1.6670, 1.6670, 1.6670],\n",
            "          ...,\n",
            "          [1.5811, 1.5811, 1.5811,  ..., 1.2900, 1.3242, 1.3408],\n",
            "          [1.5986, 1.5986, 1.5986,  ..., 1.2900, 1.3242, 1.3408],\n",
            "          [1.5986, 1.5986, 1.5986,  ..., 1.2900, 1.3242, 1.3408]],\n",
            "\n",
            "         [[1.9033, 1.9033, 1.9033,  ..., 1.8506, 1.8506, 1.8506],\n",
            "          [1.9033, 1.9033, 1.9033,  ..., 1.8506, 1.8506, 1.8506],\n",
            "          [1.9033, 1.9033, 1.9033,  ..., 1.8506, 1.8506, 1.8506],\n",
            "          ...,\n",
            "          [1.9385, 1.9385, 1.9385,  ..., 1.2910, 1.3252, 1.3428],\n",
            "          [1.9561, 1.9561, 1.9561,  ..., 1.2910, 1.3252, 1.3428],\n",
            "          [1.9561, 1.9561, 1.9561,  ..., 1.2910, 1.3252, 1.3428]],\n",
            "\n",
            "         [[1.9951, 1.9951, 1.9951,  ..., 1.9258, 1.9258, 1.9258],\n",
            "          [1.9951, 1.9951, 1.9951,  ..., 1.9258, 1.9258, 1.9258],\n",
            "          [1.9951, 1.9951, 1.9951,  ..., 1.9258, 1.9258, 1.9258],\n",
            "          ...,\n",
            "          [2.1875, 2.1875, 2.1875,  ..., 1.3506, 1.3848, 1.4023],\n",
            "          [2.2051, 2.2051, 2.2051,  ..., 1.3506, 1.3848, 1.4023],\n",
            "          [2.2051, 2.2051, 2.2051,  ..., 1.3506, 1.3848, 1.4023]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    19,   251,  6219,\n",
            "          2549,  2498,    10,  6907, 11689,   299,   136,    10,  1104,  3618,\n",
            "             4,   264,    16, 16987,   141,     7,   120,  7495,     9,  2933,\n",
            "         13820,   223,    69,  2473,     4,     2]], device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair wearing a pink bra top against a white background. She is demonstrating how to get rid of dark circles under her eyes.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair wearing a pink bra top against a white background. She is demonstrating how to get rid of dark circles under her eyes.'}\n",
            "caption_text = a woman with long brown hair wearing a pink bra top against a white background. She is demonstrating how to get rid of dark circles under her eyes., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[1.4102, 1.4102, 1.4268,  ..., 1.5986, 1.5986, 1.5986],\n",
            "          [1.4102, 1.4102, 1.4268,  ..., 1.5986, 1.5986, 1.5986],\n",
            "          [1.4268, 1.4268, 1.4443,  ..., 1.5986, 1.5986, 1.5986],\n",
            "          ...,\n",
            "          [1.8203, 1.8203, 1.8203,  ..., 1.5127, 1.4951, 1.4951],\n",
            "          [1.8555, 1.8555, 1.8555,  ..., 1.5293, 1.5127, 1.5127],\n",
            "          [1.8721, 1.8721, 1.8721,  ..., 1.5811, 1.5635, 1.5635]],\n",
            "\n",
            "         [[1.5361, 1.5361, 1.5527,  ..., 1.6934, 1.6934, 1.6934],\n",
            "          [1.5361, 1.5361, 1.5527,  ..., 1.6934, 1.6934, 1.6934],\n",
            "          [1.5527, 1.5527, 1.5703,  ..., 1.6934, 1.6934, 1.6934],\n",
            "          ...,\n",
            "          [2.0781, 2.0781, 2.0781,  ..., 1.7461, 1.7285, 1.7285],\n",
            "          [2.1133, 2.1133, 2.1133,  ..., 1.7637, 1.7461, 1.7461],\n",
            "          [2.1309, 2.1309, 2.1309,  ..., 1.8154, 1.7979, 1.7979]],\n",
            "\n",
            "         [[1.5244, 1.5244, 1.5420,  ..., 1.6992, 1.6992, 1.6992],\n",
            "          [1.5244, 1.5244, 1.5420,  ..., 1.6992, 1.6992, 1.6992],\n",
            "          [1.5420, 1.5420, 1.5596,  ..., 1.6992, 1.6992, 1.6992],\n",
            "          ...,\n",
            "          [2.3613, 2.3613, 2.3613,  ..., 2.0117, 1.9951, 1.9951],\n",
            "          [2.3965, 2.3965, 2.3965,  ..., 2.0293, 2.0117, 2.0117],\n",
            "          [2.4141, 2.4141, 2.4141,  ..., 2.0820, 2.0645, 2.0645]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,  1121,    42,  2274,    52,    64,   192,    10,   693,\n",
            "          2934,    15,     5,  1929,     8, 12681,    13,    10,  1345,     8,\n",
            "             5,  3618,    16,  1104,    11,  3195,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>In this image we can see a woman standing on the floor and posing for a photo and the background is white in color.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'In this image we can see a woman standing on the floor and posing for a photo and the background is white in color.'}\n",
            "caption_text = In this image we can see a woman standing on the floor and posing for a photo and the background is white in color., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.8848, -0.8848, -0.8677,  ...,  0.0569,  0.0569,  0.0569],\n",
            "          [-0.8848, -0.8848, -0.8677,  ...,  0.0569,  0.0569,  0.0569],\n",
            "          [-0.8848, -0.8848, -0.8677,  ...,  0.0740,  0.0740,  0.0740],\n",
            "          ...,\n",
            "          [ 0.9644,  0.9644,  0.9814,  ...,  0.6221,  0.6221,  0.6221],\n",
            "          [ 0.9814,  0.9814,  0.9990,  ...,  0.6392,  0.6392,  0.6392],\n",
            "          [ 0.9814,  0.9814,  0.9990,  ...,  0.6392,  0.6392,  0.6392]],\n",
            "\n",
            "         [[-0.9150, -0.9150, -0.8979,  ...,  0.1876,  0.1876,  0.1876],\n",
            "          [-0.9150, -0.9150, -0.8979,  ...,  0.1876,  0.1876,  0.1876],\n",
            "          [-0.9150, -0.9150, -0.8979,  ...,  0.2052,  0.2052,  0.2052],\n",
            "          ...,\n",
            "          [ 1.1855,  1.1855,  1.2031,  ...,  0.7656,  0.7656,  0.7656],\n",
            "          [ 1.2031,  1.2031,  1.2207,  ...,  0.7827,  0.7827,  0.7827],\n",
            "          [ 1.2031,  1.2031,  1.2207,  ...,  0.7827,  0.7827,  0.7827]],\n",
            "\n",
            "         [[-0.8809, -0.8809, -0.8633,  ...,  0.3743,  0.3743,  0.3743],\n",
            "          [-0.8809, -0.8809, -0.8633,  ...,  0.3743,  0.3743,  0.3743],\n",
            "          [-0.8809, -0.8809, -0.8633,  ...,  0.3916,  0.3916,  0.3916],\n",
            "          ...,\n",
            "          [ 1.4551,  1.4551,  1.4727,  ...,  0.9844,  0.9844,  0.9844],\n",
            "          [ 1.4727,  1.4727,  1.4893,  ...,  1.0020,  1.0020,  1.0020],\n",
            "          [ 1.4727,  1.4727,  1.4893,  ...,  1.0020,  1.0020,  1.0020]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    11,    10,  6907,\n",
            "          6013,   299,     8, 10844,  3051,    15,     5,  1929,    19,    10,\n",
            "          6675,    15,    69,   652,     6, 31843,    30,    10,  1109,    15,\n",
            "             5,   314,   526,     9,     5,  2274,   136,    10,  1104,  3618,\n",
            "             4,     2]], device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman in a pink tank top and jeans walking on the floor with a smile on her face, illuminated by a light on the left side of the image against a white background.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman in a pink tank top and jeans walking on the floor with a smile on her face, illuminated by a light on the left side of the image against a white background.'}\n",
            "caption_text = a woman in a pink tank top and jeans walking on the floor with a smile on her face, illuminated by a light on the left side of the image against a white background., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.4397, -0.4568, -0.4226,  ..., -1.7578, -1.7236, -1.7236],\n",
            "          [-0.4397, -0.4739, -0.4397,  ..., -1.7578, -1.7236, -1.7236],\n",
            "          [-0.4739, -0.4739, -0.4397,  ..., -1.7578, -1.7236, -1.7236],\n",
            "          ...,\n",
            "          [-0.9019, -0.9019, -0.9019,  ..., -0.9365, -0.5425, -0.5083],\n",
            "          [-0.8848, -0.8848, -0.8848,  ..., -0.9189, -0.4910, -0.4568],\n",
            "          [-0.8848, -0.8848, -0.8848,  ..., -0.9189, -0.4739, -0.4226]],\n",
            "\n",
            "         [[-0.1099, -0.1625, -0.1449,  ..., -1.8252, -1.7910, -1.7910],\n",
            "          [-0.1274, -0.1625, -0.1625,  ..., -1.8252, -1.7910, -1.7910],\n",
            "          [-0.1625, -0.1799, -0.1625,  ..., -1.8252, -1.7910, -1.7910],\n",
            "          ...,\n",
            "          [-1.3525, -1.3525, -1.3525,  ..., -1.4053, -0.9502, -0.8979],\n",
            "          [-1.3350, -1.3350, -1.3350,  ..., -1.4053, -0.8979, -0.8452],\n",
            "          [-1.3350, -1.3350, -1.3350,  ..., -1.3701, -0.8804, -0.8101]],\n",
            "\n",
            "         [[-0.1661, -0.2184, -0.2184,  ..., -1.6826, -1.6475, -1.6475],\n",
            "          [-0.1835, -0.2184, -0.2358,  ..., -1.6826, -1.6475, -1.6475],\n",
            "          [-0.2184, -0.2358, -0.2358,  ..., -1.6826, -1.6475, -1.6475],\n",
            "          ...,\n",
            "          [-1.4902, -1.4902, -1.4902,  ..., -1.5078, -1.0205, -0.9502],\n",
            "          [-1.4736, -1.4736, -1.4736,  ..., -1.4561, -0.9678, -0.8809],\n",
            "          [-1.4736, -1.4736, -1.4736,  ..., -1.4561, -0.9331, -0.8286]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   593,    62,     9,    10,\n",
            "           693,    19,   251,  6219,  2549,     8,  6219,  2473,     6,    69,\n",
            "           652,    11,  1056,   150,     5,  3618,    16, 34186,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a close up of a woman with long brown hair and brown eyes, her face in focus while the background is blurred.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a close up of a woman with long brown hair and brown eyes, her face in focus while the background is blurred.'}\n",
            "caption_text = a close up of a woman with long brown hair and brown eyes, her face in focus while the background is blurred., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[0.3311, 0.3311, 0.3481,  ..., 0.2966, 0.2966, 0.2966],\n",
            "          [0.3311, 0.3311, 0.3481,  ..., 0.2966, 0.2966, 0.2966],\n",
            "          [0.3311, 0.3311, 0.3481,  ..., 0.3137, 0.3137, 0.3137],\n",
            "          ...,\n",
            "          [0.1940, 0.1940, 0.2111,  ..., 0.0569, 0.0569, 0.0569],\n",
            "          [0.1940, 0.1940, 0.2111,  ..., 0.0398, 0.0227, 0.0227],\n",
            "          [0.1940, 0.1940, 0.2111,  ..., 0.0398, 0.0227, 0.0227]],\n",
            "\n",
            "         [[0.4502, 0.4502, 0.4678,  ..., 0.3977, 0.3977, 0.3977],\n",
            "          [0.4502, 0.4502, 0.4678,  ..., 0.3977, 0.3977, 0.3977],\n",
            "          [0.4502, 0.4502, 0.4678,  ..., 0.4153, 0.4153, 0.4153],\n",
            "          ...,\n",
            "          [0.5205, 0.5205, 0.5376,  ..., 0.1527, 0.1527, 0.1527],\n",
            "          [0.5205, 0.5205, 0.5376,  ..., 0.1351, 0.1177, 0.1177],\n",
            "          [0.5205, 0.5205, 0.5376,  ..., 0.1351, 0.1177, 0.1177]],\n",
            "\n",
            "         [[0.3044, 0.3044, 0.3220,  ..., 0.2522, 0.2522, 0.2522],\n",
            "          [0.3044, 0.3044, 0.3220,  ..., 0.2522, 0.2522, 0.2522],\n",
            "          [0.3044, 0.3044, 0.3220,  ..., 0.2695, 0.2695, 0.2695],\n",
            "          ...,\n",
            "          [0.7749, 0.7749, 0.7925,  ..., 0.1476, 0.1476, 0.1476],\n",
            "          [0.7749, 0.7749, 0.7925,  ..., 0.1302, 0.1128, 0.1128],\n",
            "          [0.7749, 0.7749, 0.7925,  ..., 0.1302, 0.1128, 0.1128]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,     0,   133,  2274,   924,    10,   693,    19,   251,\n",
            "          6219,  2549,  2498,    10,  6907,  3588,     6,  2934,    11,   760,\n",
            "             9,    10,  2204,     4,   264,    16,  2498,    10,  2007,   648,\n",
            "         14160,  7490,     6,  1969,    13,     5,  2428,   191,     4,  1405,\n",
            "          2549,    16, 25845,    11,    10,   169,    14, 16420,    69,   652,\n",
            "             8,  3639,    10,  2842,     9, 32595,     7,    69,   356,     4,\n",
            "             2]], device='cuda:0')\n",
            "generated_text: </s><s><s>The image shows a woman with long brown hair wearing a pink dress, standing in front of a wall. She is wearing a simple yet stylish outfit, perfect for the spring season. Her hair is styled in a way that frames her face and adds a touch of elegance to her look.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair wearing a pink dress, standing in front of a wall. She is wearing a simple yet stylish outfit, perfect for the spring season. Her hair is styled in a way that frames her face and adds a touch of elegance to her look.'}\n",
            "caption_text = a woman with long brown hair wearing a pink dress, standing in front of a wall. She is wearing a simple yet stylish outfit, perfect for the spring season. Her hair is styled in a way that frames her face and adds a touch of elegance to her look., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[ 0.0912,  0.0912,  0.1083,  ..., -0.1315, -0.1315, -0.1315],\n",
            "          [ 0.0912,  0.0912,  0.1083,  ..., -0.1315, -0.1315, -0.1315],\n",
            "          [ 0.0912,  0.0912,  0.1083,  ..., -0.1315, -0.1315, -0.1315],\n",
            "          ...,\n",
            "          [-0.1656, -0.1656, -0.1656,  ..., -0.6450, -0.6621, -0.6621],\n",
            "          [-0.1656, -0.1656, -0.1656,  ..., -0.6450, -0.6621, -0.6621],\n",
            "          [-0.1656, -0.1656, -0.1656,  ..., -0.6450, -0.6621, -0.6621]],\n",
            "\n",
            "         [[ 0.2578,  0.2578,  0.2751,  ...,  0.0651,  0.0651,  0.0651],\n",
            "          [ 0.2578,  0.2578,  0.2751,  ...,  0.0651,  0.0651,  0.0651],\n",
            "          [ 0.2578,  0.2578,  0.2751,  ...,  0.0651,  0.0651,  0.0651],\n",
            "          ...,\n",
            "          [ 0.0476,  0.0476,  0.0476,  ..., -1.1953, -1.2129, -1.2129],\n",
            "          [ 0.0476,  0.0476,  0.0476,  ..., -1.1953, -1.2129, -1.2129],\n",
            "          [ 0.0476,  0.0476,  0.0476,  ..., -1.1953, -1.2129, -1.2129]],\n",
            "\n",
            "         [[ 0.2347,  0.2347,  0.2522,  ..., -0.0092, -0.0092, -0.0092],\n",
            "          [ 0.2347,  0.2347,  0.2522,  ..., -0.0092, -0.0092, -0.0092],\n",
            "          [ 0.2347,  0.2347,  0.2522,  ..., -0.0092, -0.0092, -0.0092],\n",
            "          ...,\n",
            "          [ 0.1650,  0.1650,  0.1650,  ..., -1.3691, -1.3857, -1.3857],\n",
            "          [ 0.1650,  0.1650,  0.1650,  ..., -1.3691, -1.3857, -1.3857],\n",
            "          [ 0.1650,  0.1650,  0.1650,  ..., -1.3691, -1.3857, -1.3857]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    19,   251,  6219,\n",
            "          2549,  2498,    10,  6907,  3588,     8,    10,  1763,     9,  4334,\n",
            "          5567, 19706,     4,    20,  3618,    16,  2829, 34186,     6,  1311,\n",
            "             5,  2274,    10,  3366,   219,   619,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair wearing a pink dress and a pair of silver earrings. The background is slightly blurred, giving the image a dreamy feel.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair wearing a pink dress and a pair of silver earrings. The background is slightly blurred, giving the image a dreamy feel.'}\n",
            "caption_text = a woman with long brown hair wearing a pink dress and a pair of silver earrings. The background is slightly blurred, giving the image a dreamy feel., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.6279, -0.6450, -0.6108,  ..., -0.6792, -0.6792, -0.7139],\n",
            "          [-0.6279, -0.6108, -0.6279,  ..., -0.6968, -0.6792, -0.6792],\n",
            "          [-0.6108, -0.6108, -0.6279,  ..., -0.6792, -0.6621, -0.7139],\n",
            "          ...,\n",
            "          [ 1.3584,  1.3760,  1.4102,  ..., -1.0732, -1.0215, -0.9707],\n",
            "          [ 1.3926,  1.3926,  1.4443,  ..., -1.0732, -1.0391, -0.9707],\n",
            "          [ 1.3926,  1.3760,  1.4268,  ..., -1.0566, -1.0391, -1.0049]],\n",
            "\n",
            "         [[-0.4602, -0.4775, -0.4602,  ..., -0.6353, -0.6177, -0.6353],\n",
            "          [-0.4602, -0.4426, -0.4602,  ..., -0.6353, -0.6353, -0.6353],\n",
            "          [-0.4426, -0.4602, -0.4426,  ..., -0.6177, -0.6353, -0.6353],\n",
            "          ...,\n",
            "          [ 0.7305,  0.7305,  0.7480,  ..., -1.4756, -1.3877, -1.2832],\n",
            "          [ 0.7480,  0.7305,  0.7656,  ..., -1.4580, -1.3701, -1.3008],\n",
            "          [ 0.7305,  0.7480,  0.7656,  ..., -1.5107, -1.4053, -1.2832]],\n",
            "\n",
            "         [[-0.4624, -0.4624, -0.4451,  ..., -0.7236, -0.7065, -0.7065],\n",
            "          [-0.4451, -0.4451, -0.4624,  ..., -0.7065, -0.7236, -0.7236],\n",
            "          [-0.4451, -0.4275, -0.4451,  ..., -0.6890, -0.6714, -0.6890],\n",
            "          ...,\n",
            "          [ 0.2695,  0.3044,  0.3394,  ..., -1.5605, -1.4902, -1.3340],\n",
            "          [ 0.2522,  0.2871,  0.3567,  ..., -1.5430, -1.4561, -1.3516],\n",
            "          [ 0.2871,  0.2871,  0.3394,  ..., -1.5605, -1.4736, -1.3340]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    19,   251,  6219,\n",
            "          2549, 12382,    23,     5,  2280,   136,    10, 34186,  3618,     4,\n",
            "             2]], device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair smiling at the camera against a blurred background.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair smiling at the camera against a blurred background.'}\n",
            "caption_text = a woman with long brown hair smiling at the camera against a blurred background., concept_sentence=K3rryN30n\n",
            "Creating dataset\n",
            "resize datasets/kerry-neon/Kerry00031.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00031.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00031.txt, original_caption=K3rryN30n a woman sitting on a couch with her legs crossed, wearing a pink bodysuit. She is surrounded by cushions and there is a wall in the background.\n",
            "resize datasets/kerry-neon/Kerry00028.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00028.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00028.txt, original_caption=K3rryN30n a woman in a black suit posing for a picture against a white background. She is wearing a black blazer, giving her a sophisticated and stylish look. Her hair is styled in a sleek and sophisticated manner, and her makeup is subtle yet glamorous. She looks confident and poised, ready to take on the world.\n",
            "resize datasets/kerry-neon/Kerry00022.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00022.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00022.txt, original_caption=K3rryN30n a woman in a pink dress sitting on a couch, with a wall in the background. She is wearing makeup, which is one of the 10 best makeup looks for every skin tone. Her eyes are highlighted with a subtle smoky eye look, her lips are painted a glossy pink, and her cheeks are contoured with a light pink blush. Her hair is styled in loose waves, and she is wearing minimal makeup.\n",
            "resize datasets/kerry-neon/Kerry00021.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00021.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00021.txt, original_caption=K3rryN30n a woman standing in a hallway with her hands on her hips, wearing a pink tank top and jeans. The background is slightly blurred, and there is a black object in the background.\n",
            "resize datasets/kerry-neon/Kerry00016.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00016.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00016.txt, original_caption=K3rryN30n a woman with long brown hair wearing a pink dress, standing in front of a wall. She has a confident stance and her hair is styled in a way that frames her face. Her dress is a light pink color and has a scoop neckline. The wall behind her is a neutral color and is painted a light shade of pink.\n",
            "resize datasets/kerry-neon/Kerry00017.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00017.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00017.txt, original_caption=K3rryN30n a woman with long brown hair wearing a pink bra top, standing in front of a wall. She has a confident and determined expression on her face, and her posture is strong and proud. Her hair is styled in a way that frames her face and accentuates her features. The wall behind her is plain and white, providing a neutral backdrop for her outfit.\n",
            "resize datasets/kerry-neon/Kerry00013.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00013.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00013.txt, original_caption=K3rryN30n a woman in a pink dress smiling at the camera against a white background. She is identified as Jessica Alba, and the image was taken by a professional photographer.\n",
            "resize datasets/kerry-neon/Kerry00011.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00011.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00011.txt, original_caption=K3rryN30n a woman walking down a hallway in a pink tank top and jeans, with a black object on the left side of the image and a wall and door in the background.\n",
            "resize datasets/kerry-neon/Kerry00009.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00009.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00009.txt, original_caption=K3rryN30n a woman with long brown hair looking directly at the camera against a dark background.\n",
            "resize datasets/kerry-neon/Kerry00007.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00007.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00007.txt, original_caption=K3rryN30n a woman with long brown hair wearing a pink bra top against a white background. She is demonstrating how to get rid of dark circles under her eyes.\n",
            "resize datasets/kerry-neon/Kerry00006.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00006.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00006.txt, original_caption=K3rryN30n In this image we can see a woman standing on the floor and posing for a photo and the background is white in color.\n",
            "resize datasets/kerry-neon/Kerry00005.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00005.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00005.txt, original_caption=K3rryN30n a woman in a pink tank top and jeans walking on the floor with a smile on her face, illuminated by a light on the left side of the image against a white background.\n",
            "resize datasets/kerry-neon/Kerry00004.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00004.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00004.txt, original_caption=K3rryN30n a close up of a woman with long brown hair and brown eyes, her face in focus while the background is blurred.\n",
            "resize datasets/kerry-neon/Kerry00003.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00003.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00003.txt, original_caption=K3rryN30n a woman with long brown hair wearing a pink dress, standing in front of a wall. She is wearing a simple yet stylish outfit, perfect for the spring season. Her hair is styled in a way that frames her face and adds a touch of elegance to her look.\n",
            "resize datasets/kerry-neon/Kerry00002.jpg : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00002.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00002.txt, original_caption=K3rryN30n a woman with long brown hair wearing a pink dress and a pair of silver earrings. The background is slightly blurred, giving the image a dreamy feel.\n",
            "resize datasets/kerry-neon/Kerry00001.png : 512x512\n",
            "image_path=datasets/kerry-neon/Kerry00001.png, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00001.txt, original_caption=K3rryN30n a woman with long brown hair smiling at the camera against a blurred background.\n",
            "destination_folder datasets/kerry-neon\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2709, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fluxgym-Colab/app.py\", line 651, in <module>\n",
            "    demo.launch(show_error=True, allowed_paths=[cwd], share=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2614, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2713, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\", line 68, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d5b76ad5958d846475.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the corrupted file\n",
        "!rm /content/fluxgym-Colab/models/clip/t5xxl_fp8.safetensors\n",
        "\n",
        "# Download the correct T5 model\n",
        "%cd /content/fluxgym-Colab/models/clip\n",
        "!wget https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8.safetensors\n",
        "\n",
        "# If that fails, try this alternative:\n",
        "!wget https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder_2.safetensors -O t5xxl_fp8.safetensors\n"
      ],
      "metadata": {
        "id": "9VbI5mKqlrSC",
        "outputId": "81feb92d-ff4a-4ccc-a948-0ef81893a5ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab/models/clip\n",
            "--2025-06-20 23:05:14--  https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.16, 18.239.50.80, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-06-20 23:05:15 ERROR 404: Not Found.\n",
            "\n",
            "--2025-06-20 23:05:15--  https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder_2.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.16, 18.239.50.80, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "\n",
            "Username/Password Authentication Failed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the T5 text encoder\n",
        "print(\"Select and upload t5xxl_fp8_e4m3fn.safetensors:\")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "K1pZ5ApMn_OH",
        "outputId": "8dfacee8-1f58-4c26-baed-cda2743b1621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select and upload t5xxl_fp8_e4m3fn.safetensors:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e277fe62-62e5-4306-b2e5-819cdbf84e2f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e277fe62-62e5-4306-b2e5-819cdbf84e2f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FOvMLmaYsHkV",
        "outputId": "e6a72a4d-c466-43bb-bad1-1821a968861c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy T5 model\n",
        "!cp \"/content/drive/MyDrive/FluxGym Models/t5xxl_fp8_e4m3fn.safetensors\" \"/content/fluxgym-Colab/models/clip/t5xxl_fp8.safetensors\"\n",
        "\n",
        "# Copy VAE model\n",
        "!cp \"/content/drive/MyDrive/FluxGym Models/ae.safetensors\" \"/content/fluxgym-Colab/models/vae/ae.sft\"\n",
        "\n",
        "# Verify files\n",
        "!ls -la /content/fluxgym-Colab/models/clip/\n",
        "!ls -la /content/fluxgym-Colab/models/vae/"
      ],
      "metadata": {
        "id": "4f9SK3SRsPrz",
        "outputId": "191c8d4e-2950-4cd7-ab2a-8d22d1f0715d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/FluxGym Models/t5xxl_fp8_e4m3fn.safetensors': No such file or directory\n",
            "cp: cannot stat '/content/drive/MyDrive/FluxGym Models/ae.safetensors': No such file or directory\n",
            "total 5260000\n",
            "drwxr-xr-x 2 root root       4096 Jun 20 23:05 .\n",
            "drwxr-xr-x 5 root root       4096 Jun 20 22:14 ..\n",
            "-rw-r--r-- 1 root root  246144152 Aug  1  2024 clip_l.safetensors\n",
            "-rw-r--r-- 1 root root  246144152 Aug  1  2024 clip_l.safetensors.1\n",
            "-rw-r--r-- 1 root root          0 Jun 20 22:14 .gitkeep\n",
            "-rw-r--r-- 1 root root 4893934904 Aug  1  2024 t5xxl_fp16.safetensors\n",
            "-rw-r--r-- 1 root root          0 Jun 20 23:05 t5xxl_fp8.safetensors\n",
            "total 327460\n",
            "drwxr-xr-x 2 root root      4096 Jun 20 22:52 .\n",
            "drwxr-xr-x 5 root root      4096 Jun 20 22:14 ..\n",
            "-rw-r--r-- 1 root root         0 Jun 20 22:59 ae.sft\n",
            "-rw-r--r-- 1 root root 335304388 Aug  1  2024 ae.sft.1\n",
            "-rw-r--r-- 1 root root         0 Jun 20 22:14 .gitkeep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the existing t5xxl_fp16 model (rename to what FluxGym expects)\n",
        "!cp /content/fluxgym-Colab/models/clip/t5xxl_fp16.safetensors /content/fluxgym-Colab/models/clip/t5xxl_fp8.safetensors\n",
        "\n",
        "# Use the existing VAE file\n",
        "!cp /content/fluxgym-Colab/models/vae/ae.sft.1 /content/fluxgym-Colab/models/vae/ae.sft\n",
        "\n",
        "# Verify the files now have content\n",
        "!ls -la /content/fluxgym-Colab/models/clip/t5xxl_fp8.safetensors\n",
        "!ls -la /content/fluxgym-Colab/models/vae/ae.sft\n"
      ],
      "metadata": {
        "id": "ScpZ4Cftsd95",
        "outputId": "ac33f393-b9ae-4772-e0a1-253ed341db20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 4893934904 Jun 20 23:35 /content/fluxgym-Colab/models/clip/t5xxl_fp8.safetensors\n",
            "-rw-r--r-- 1 root root 335304388 Jun 20 23:35 /content/fluxgym-Colab/models/vae/ae.sft\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/fluxgym-Colab\n",
        "!python app.py --share --listen 0.0.0.0 --port 7860"
      ],
      "metadata": {
        "id": "XMC42CNFs2S7",
        "outputId": "2171e116-10fd-4264-bb29-ee0875d47f0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab\n",
            "2025-06-20 23:36:38.923366: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750462598.947074   22606 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750462598.953659   22606 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-20 23:36:38.976457: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://80948d1ca11827af0a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "launched\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rry, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rry, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rryN, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rryN, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rryN3, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rryN30n, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rryN30n, sample_every_n_steps=0\n",
            "gen_sh: network_dim:4, max_train_epochs=16, save_every_n_epochs=4, timestep_sampling=shift, guidance_scale=1, vram=20G, sample_prompts=K3rryN30n, sample_every_n_steps=0\n",
            "max_train_epochs=16 num_images=13, num_repeats=10, total_steps=2080\n",
            "run_captioning\n",
            "concept sentence K3rryN30n\n",
            "captions ('K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', 'K3rryN30n', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '')\n",
            "device=cuda\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[1.7861, 1.7861, 1.7861,  ..., 1.7520, 1.7520, 1.7520],\n",
            "          [1.7861, 1.7861, 1.7861,  ..., 1.7520, 1.7520, 1.7520],\n",
            "          [1.7861, 1.7861, 1.7861,  ..., 1.7520, 1.7520, 1.7520],\n",
            "          ...,\n",
            "          [1.7695, 1.7695, 1.7695,  ..., 1.5811, 1.5811, 1.5811],\n",
            "          [1.7695, 1.7695, 1.7695,  ..., 1.5811, 1.5811, 1.5811],\n",
            "          [1.7695, 1.7695, 1.7695,  ..., 1.5811, 1.5811, 1.5811]],\n",
            "\n",
            "         [[2.0254, 2.0254, 2.0254,  ..., 2.0254, 2.0254, 2.0254],\n",
            "          [2.0254, 2.0254, 2.0254,  ..., 2.0254, 2.0254, 2.0254],\n",
            "          [2.0254, 2.0254, 2.0254,  ..., 2.0254, 2.0254, 2.0254],\n",
            "          ...,\n",
            "          [2.0430, 2.0430, 2.0430,  ..., 1.7637, 1.7637, 1.7637],\n",
            "          [2.0430, 2.0430, 2.0430,  ..., 1.7637, 1.7637, 1.7637],\n",
            "          [2.0430, 2.0430, 2.0430,  ..., 1.7637, 1.7637, 1.7637]],\n",
            "\n",
            "         [[2.2559, 2.2559, 2.2559,  ..., 2.2383, 2.2383, 2.2383],\n",
            "          [2.2559, 2.2559, 2.2559,  ..., 2.2383, 2.2383, 2.2383],\n",
            "          [2.2559, 2.2559, 2.2559,  ..., 2.2383, 2.2383, 2.2383],\n",
            "          ...,\n",
            "          [2.2559, 2.2559, 2.2559,  ..., 1.8730, 1.8730, 1.8730],\n",
            "          [2.2559, 2.2559, 2.2559,  ..., 1.8730, 1.8730, 1.8730],\n",
            "          [2.2559, 2.2559, 2.2559,  ..., 1.8730, 1.8730, 1.8730]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,  2934,   136,    10,\n",
            "          1104,  3618,  2498,    10, 31430,  1458, 14966,  5134,  6013,   299,\n",
            "             8,   909,  9304,     4,    20,  6013,   299,    34,    10, 15500,\n",
            "          5397,  1902,     8,  7174, 31622,     6,     8,     5, 10199,    34,\n",
            "            10,  3793,     6, 14966,  5134, 18632,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman standing against a white background wearing a dusty rose ribbed tank top and black pants. The tank top has a scoop neckline and thin straps, and the fabric has a soft, ribbed texture.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman standing against a white background wearing a dusty rose ribbed tank top and black pants. The tank top has a scoop neckline and thin straps, and the fabric has a soft, ribbed texture.'}\n",
            "caption_text = a woman standing against a white background wearing a dusty rose ribbed tank top and black pants. The tank top has a scoop neckline and thin straps, and the fabric has a soft, ribbed texture., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.5254, -0.5254, -0.5083,  ..., -1.4844, -1.4844, -1.4844],\n",
            "          [-0.5254, -0.5254, -0.5083,  ..., -1.4844, -1.4844, -1.4844],\n",
            "          [-0.5083, -0.5083, -0.4910,  ..., -1.4844, -1.4844, -1.4844],\n",
            "          ...,\n",
            "          [-1.9639, -1.9463, -1.9297,  ..., -1.7754, -1.7754, -1.7578],\n",
            "          [-1.9639, -1.9463, -1.9297,  ..., -1.8096, -1.7930, -1.7754],\n",
            "          [-1.9639, -1.9463, -1.9297,  ..., -1.8096, -1.8096, -1.7754]],\n",
            "\n",
            "         [[-0.3726, -0.3726, -0.3550,  ..., -1.3525, -1.3525, -1.3525],\n",
            "          [-0.3726, -0.3726, -0.3550,  ..., -1.3525, -1.3525, -1.3525],\n",
            "          [-0.3550, -0.3550, -0.3376,  ..., -1.3525, -1.3525, -1.3525],\n",
            "          ...,\n",
            "          [-1.8086, -1.7910, -1.7734,  ..., -1.5801, -1.5977, -1.5977],\n",
            "          [-1.8086, -1.7910, -1.7734,  ..., -1.6152, -1.6152, -1.6152],\n",
            "          [-1.8086, -1.7910, -1.7734,  ..., -1.6152, -1.6328, -1.6152]],\n",
            "\n",
            "         [[-0.3926, -0.3926, -0.3752,  ..., -1.3691, -1.3691, -1.3691],\n",
            "          [-0.3926, -0.3926, -0.3752,  ..., -1.3691, -1.3691, -1.3691],\n",
            "          [-0.3752, -0.3752, -0.3579,  ..., -1.3691, -1.3691, -1.3691],\n",
            "          ...,\n",
            "          [-1.5605, -1.5430, -1.5254,  ..., -1.3857, -1.3857, -1.3857],\n",
            "          [-1.5605, -1.5430, -1.5254,  ..., -1.4209, -1.4209, -1.4033],\n",
            "          [-1.5605, -1.5430, -1.5254,  ..., -1.4209, -1.4209, -1.4033]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    11,    10,  6907,\n",
            "          3588,  2828,    15,    10, 16433,     6,    19,    10,  2204,    11,\n",
            "             5,  3618,     4,   264,    16,  2498,  7855,     6,    61,    16,\n",
            "            65,     9,     5,   158,   275,  7855,  1326,    13,   358,  3024,\n",
            "          6328,     4,  1405,  2473,    32,  6263,    19,    10, 12405,  5278,\n",
            "         24878,  2295,   356,     6,    69, 14638,    32, 10122,    10, 29282,\n",
            "          6907,     6,     8,    69, 32040,    32,  8541,  8855,    19,    10,\n",
            "          1109,  6907, 33556,     4,  1405,  2549,    16, 25845,    11,  7082,\n",
            "          6995,     6,     8,    79,    16,  2498,  9865,  7855,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman in a pink dress sitting on a couch, with a wall in the background. She is wearing makeup, which is one of the 10 best makeup looks for every skin tone. Her eyes are highlighted with a subtle smoky eye look, her lips are painted a glossy pink, and her cheeks are contoured with a light pink blush. Her hair is styled in loose waves, and she is wearing minimal makeup.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman in a pink dress sitting on a couch, with a wall in the background. She is wearing makeup, which is one of the 10 best makeup looks for every skin tone. Her eyes are highlighted with a subtle smoky eye look, her lips are painted a glossy pink, and her cheeks are contoured with a light pink blush. Her hair is styled in loose waves, and she is wearing minimal makeup.'}\n",
            "caption_text = a woman in a pink dress sitting on a couch, with a wall in the background. She is wearing makeup, which is one of the 10 best makeup looks for every skin tone. Her eyes are highlighted with a subtle smoky eye look, her lips are painted a glossy pink, and her cheeks are contoured with a light pink blush. Her hair is styled in loose waves, and she is wearing minimal makeup., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[1.5635, 1.5635, 1.5635,  ..., 1.6152, 1.6152, 1.6152],\n",
            "          [1.5635, 1.5635, 1.5635,  ..., 1.6152, 1.6152, 1.6152],\n",
            "          [1.5635, 1.5635, 1.5635,  ..., 1.6152, 1.6152, 1.6152],\n",
            "          ...,\n",
            "          [1.2383, 1.2725, 1.2725,  ..., 1.4268, 1.4268, 1.4268],\n",
            "          [1.2559, 1.2559, 1.2900,  ..., 1.4268, 1.4268, 1.4268],\n",
            "          [1.2559, 1.2725, 1.2900,  ..., 1.4268, 1.4268, 1.4268]],\n",
            "\n",
            "         [[1.7637, 1.7637, 1.7637,  ..., 1.7461, 1.7461, 1.7461],\n",
            "          [1.7637, 1.7637, 1.7637,  ..., 1.7461, 1.7461, 1.7461],\n",
            "          [1.7637, 1.7637, 1.7637,  ..., 1.7461, 1.7461, 1.7461],\n",
            "          ...,\n",
            "          [1.4307, 1.4658, 1.4658,  ..., 1.8154, 1.8154, 1.8154],\n",
            "          [1.4482, 1.4482, 1.4834,  ..., 1.8154, 1.8154, 1.8154],\n",
            "          [1.4482, 1.4658, 1.4834,  ..., 1.8154, 1.8154, 1.8154]],\n",
            "\n",
            "         [[1.7510, 1.7510, 1.7510,  ..., 1.7334, 1.7334, 1.7334],\n",
            "          [1.7510, 1.7510, 1.7510,  ..., 1.7334, 1.7334, 1.7334],\n",
            "          [1.7510, 1.7510, 1.7510,  ..., 1.7334, 1.7334, 1.7334],\n",
            "          ...,\n",
            "          [1.6289, 1.6641, 1.6641,  ..., 2.1699, 2.1699, 2.1699],\n",
            "          [1.6465, 1.6465, 1.6816,  ..., 2.1699, 2.1699, 2.1699],\n",
            "          [1.6465, 1.6641, 1.6816,  ..., 2.1699, 2.1699, 2.1699]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    11,    10,  6907,\n",
            "          6013,   299,     8,   909, 13344, 12681,    13,    10,  2170,   136,\n",
            "            10,  1104,  3618,     4,   264,  2092,     7,    28,    11,     5,\n",
            "          1692,     9,    10, 11025,  1852,     6,    19,    69,  3701,    66,\n",
            "         34513,     8,    69,   471, 36301,  2829,     7,     5,   526,     4,\n",
            "          1405,  2549,    16,  2468,   124,    11,    10, 21761, 17624,     8,\n",
            "            79,    34,    10,  7053,  8151,    15,    69,   652,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman in a pink tank top and black shorts posing for a picture against a white background. She appears to be in the middle of a yoga session, with her arms outstretched and her head tilted slightly to the side. Her hair is pulled back in a ponytail and she has a peaceful expression on her face.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman in a pink tank top and black shorts posing for a picture against a white background. She appears to be in the middle of a yoga session, with her arms outstretched and her head tilted slightly to the side. Her hair is pulled back in a ponytail and she has a peaceful expression on her face.'}\n",
            "caption_text = a woman in a pink tank top and black shorts posing for a picture against a white background. She appears to be in the middle of a yoga session, with her arms outstretched and her head tilted slightly to the side. Her hair is pulled back in a ponytail and she has a peaceful expression on her face., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[ 0.2625,  0.2625,  0.2625,  ..., -0.2683, -0.2856, -0.2856],\n",
            "          [ 0.2625,  0.2625,  0.2625,  ..., -0.2683, -0.2856, -0.2856],\n",
            "          [ 0.2795,  0.2795,  0.2795,  ..., -0.2512, -0.2683, -0.2683],\n",
            "          ...,\n",
            "          [-0.6279, -0.6279, -0.6450,  ..., -0.2512, -0.2683, -0.2683],\n",
            "          [-0.6108, -0.6108, -0.6279,  ..., -0.2512, -0.2683, -0.2683],\n",
            "          [-0.6108, -0.6108, -0.6279,  ..., -0.2512, -0.2683, -0.2683]],\n",
            "\n",
            "         [[ 0.4502,  0.4502,  0.4502,  ..., -0.0224, -0.0399, -0.0399],\n",
            "          [ 0.4502,  0.4502,  0.4502,  ..., -0.0224, -0.0399, -0.0399],\n",
            "          [ 0.4678,  0.4678,  0.4678,  ..., -0.0049, -0.0224, -0.0224],\n",
            "          ...,\n",
            "          [-0.5479, -0.5479, -0.5649,  ..., -0.0049, -0.0224, -0.0224],\n",
            "          [-0.5303, -0.5303, -0.5479,  ..., -0.0049, -0.0224, -0.0224],\n",
            "          [-0.5303, -0.5303, -0.5479,  ..., -0.0049, -0.0224, -0.0224]],\n",
            "\n",
            "         [[ 0.5483,  0.5483,  0.5483,  ...,  0.0605,  0.0431,  0.0431],\n",
            "          [ 0.5483,  0.5483,  0.5483,  ...,  0.0605,  0.0431,  0.0431],\n",
            "          [ 0.5659,  0.5659,  0.5659,  ...,  0.0779,  0.0605,  0.0605],\n",
            "          ...,\n",
            "          [-0.5845, -0.5845, -0.6021,  ...,  0.0953,  0.0779,  0.0779],\n",
            "          [-0.5669, -0.5669, -0.5845,  ...,  0.0953,  0.0779,  0.0779],\n",
            "          [-0.5669, -0.5669, -0.5845,  ...,  0.0953,  0.0779,  0.0779]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    11,    10,  6907,\n",
            "          6013,   299,     8,  2440, 10844,    19,    69,  1420,    66, 34513,\n",
            "             6,  2934,    11,   760,     9,    10,  2204,     4,   264,  2092,\n",
            "             7,    28,    11,     5,  1692,     9,    41,  1194,     6,    25,\n",
            "          4658,    30,     5,  1270,     9,     5,  2274,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman in a pink tank top and blue jeans with her hands outstretched, standing in front of a wall. She appears to be in the middle of an interview, as indicated by the title of the image.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman in a pink tank top and blue jeans with her hands outstretched, standing in front of a wall. She appears to be in the middle of an interview, as indicated by the title of the image.'}\n",
            "caption_text = a woman in a pink tank top and blue jeans with her hands outstretched, standing in front of a wall. She appears to be in the middle of an interview, as indicated by the title of the image., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[ 0.2795,  0.2795,  0.2966,  ...,  0.2111,  0.1940,  0.1940],\n",
            "          [ 0.2795,  0.2795,  0.2966,  ...,  0.2111,  0.1940,  0.1940],\n",
            "          [ 0.2795,  0.2795,  0.2966,  ...,  0.2111,  0.1940,  0.1940],\n",
            "          ...,\n",
            "          [-0.4397, -0.4397, -0.4226,  ..., -0.3711, -0.3711, -0.3711],\n",
            "          [-0.4226, -0.4226, -0.4055,  ..., -0.3882, -0.3882, -0.3882],\n",
            "          [-0.4226, -0.4226, -0.4055,  ..., -0.3882, -0.3882, -0.3882]],\n",
            "\n",
            "         [[ 0.4329,  0.4329,  0.4502,  ...,  0.3276,  0.3103,  0.3103],\n",
            "          [ 0.4329,  0.4329,  0.4502,  ...,  0.3276,  0.3103,  0.3103],\n",
            "          [ 0.4329,  0.4329,  0.4502,  ...,  0.3276,  0.3103,  0.3103],\n",
            "          ...,\n",
            "          [-0.3025, -0.3025, -0.2849,  ..., -0.2849, -0.2849, -0.2849],\n",
            "          [-0.2849, -0.2849, -0.2676,  ..., -0.3025, -0.3025, -0.3025],\n",
            "          [-0.2849, -0.2849, -0.2676,  ..., -0.3025, -0.3025, -0.3025]],\n",
            "\n",
            "         [[ 0.3394,  0.3394,  0.3567,  ...,  0.2000,  0.1825,  0.1825],\n",
            "          [ 0.3394,  0.3394,  0.3567,  ...,  0.2000,  0.1825,  0.1825],\n",
            "          [ 0.3394,  0.3394,  0.3567,  ...,  0.2000,  0.1825,  0.1825],\n",
            "          ...,\n",
            "          [-0.1835, -0.1835, -0.1661,  ..., -0.3230, -0.3230, -0.3230],\n",
            "          [-0.1661, -0.1661, -0.1487,  ..., -0.3403, -0.3403, -0.3403],\n",
            "          [-0.1661, -0.1661, -0.1487,  ..., -0.3403, -0.3403, -0.3403]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    11,    10,  6907,\n",
            "          3588, 12382,    23,     5,  2280,   136,    10,  1104,  3618,     4,\n",
            "           264,    16,  2006,    25,  7103,   726,  3178,     6,     8,     5,\n",
            "          2274,    21,   551,    30,    10,  2038,  9463,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman in a pink dress smiling at the camera against a white background. She is identified as Jessica Alba, and the image was taken by a professional photographer.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman in a pink dress smiling at the camera against a white background. She is identified as Jessica Alba, and the image was taken by a professional photographer.'}\n",
            "caption_text = a woman in a pink dress smiling at the camera against a white background. She is identified as Jessica Alba, and the image was taken by a professional photographer., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[ 0.5708,  0.5708,  0.5879,  ...,  0.6904,  0.6733,  0.6733],\n",
            "          [ 0.5708,  0.5708,  0.5879,  ...,  0.6904,  0.6733,  0.6733],\n",
            "          [ 0.5708,  0.5708,  0.5879,  ...,  0.7075,  0.6904,  0.6904],\n",
            "          ...,\n",
            "          [-0.3369, -0.5254, -0.6450,  ...,  0.5020,  0.5879,  0.6392],\n",
            "          [-0.3711, -0.5425, -0.6621,  ...,  0.5366,  0.6221,  0.6733],\n",
            "          [-0.3711, -0.5425, -0.6621,  ...,  0.5537,  0.6221,  0.6733]],\n",
            "\n",
            "         [[ 0.8003,  0.8003,  0.8179,  ...,  0.9229,  0.9053,  0.9053],\n",
            "          [ 0.8003,  0.8003,  0.8179,  ...,  0.9229,  0.9053,  0.9053],\n",
            "          [ 0.8003,  0.8003,  0.8179,  ...,  0.9404,  0.9229,  0.9229],\n",
            "          ...,\n",
            "          [-0.5825, -0.7754, -0.9502,  ...,  0.1002,  0.3452,  0.5205],\n",
            "          [-0.6001, -0.7925, -0.9678,  ...,  0.1351,  0.3804,  0.5552],\n",
            "          [-0.6177, -0.7925, -0.9854,  ...,  0.1527,  0.3977,  0.5728]],\n",
            "\n",
            "         [[ 0.9146,  0.9146,  0.9321,  ...,  1.0713,  1.0537,  1.0537],\n",
            "          [ 0.9146,  0.9146,  0.9321,  ...,  1.0713,  1.0537,  1.0537],\n",
            "          [ 0.9146,  0.9146,  0.9321,  ...,  1.0889,  1.0713,  1.0713],\n",
            "          ...,\n",
            "          [-0.7236, -0.9155, -1.0898,  ..., -0.0964,  0.2695,  0.5483],\n",
            "          [-0.7412, -0.9331, -1.0898,  ..., -0.0615,  0.3044,  0.5835],\n",
            "          [-0.7588, -0.9331, -1.1074,  ..., -0.0441,  0.3220,  0.5835]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[   2,    0,  133, 2274,  924,   10,  693,   19,  251, 6219, 2549, 2498,\n",
            "           10,  909,  299,    6, 2934,   11,  760,    9,   10, 2204,    4,  264,\n",
            "         2092,    7,   28,   11,    5, 1692,    9,   41, 1194,    6,   25, 4658,\n",
            "           30,    5, 1270,    9,    5, 2274,    4,    2]], device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair wearing a black top, standing in front of a wall. She appears to be in the middle of an interview, as indicated by the title of the image.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair wearing a black top, standing in front of a wall. She appears to be in the middle of an interview, as indicated by the title of the image.'}\n",
            "caption_text = a woman with long brown hair wearing a black top, standing in front of a wall. She appears to be in the middle of an interview, as indicated by the title of the image., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-2.0488, -2.0488, -2.0488,  ..., -2.0156, -2.0156, -2.0156],\n",
            "          [-2.0488, -2.0488, -2.0488,  ..., -2.0156, -2.0156, -2.0156],\n",
            "          [-2.0488, -2.0488, -2.0488,  ..., -2.0156, -2.0156, -2.0156],\n",
            "          ...,\n",
            "          [-2.0664, -2.0664, -2.0664,  ..., -1.9121, -1.9297, -1.9297],\n",
            "          [-2.0664, -2.0664, -2.0664,  ..., -1.9121, -1.9297, -1.9297],\n",
            "          [-2.0664, -2.0664, -2.0664,  ..., -1.9121, -1.9297, -1.9297]],\n",
            "\n",
            "         [[-1.9658, -1.9658, -1.9658,  ..., -1.8955, -1.8955, -1.8955],\n",
            "          [-1.9658, -1.9658, -1.9658,  ..., -1.8955, -1.8955, -1.8955],\n",
            "          [-1.9658, -1.9658, -1.9658,  ..., -1.8955, -1.8955, -1.8955],\n",
            "          ...,\n",
            "          [-1.9834, -1.9834, -1.9834,  ..., -1.8779, -1.8955, -1.8955],\n",
            "          [-1.9834, -1.9834, -1.9834,  ..., -1.8779, -1.8955, -1.8955],\n",
            "          [-1.9834, -1.9834, -1.9834,  ..., -1.8779, -1.8955, -1.8955]],\n",
            "\n",
            "         [[-1.7344, -1.7344, -1.7344,  ..., -1.6826, -1.6826, -1.6826],\n",
            "          [-1.7344, -1.7344, -1.7344,  ..., -1.6826, -1.6826, -1.6826],\n",
            "          [-1.7344, -1.7344, -1.7344,  ..., -1.6826, -1.6826, -1.6826],\n",
            "          ...,\n",
            "          [-1.7520, -1.7520, -1.7520,  ..., -1.7344, -1.7520, -1.7520],\n",
            "          [-1.7520, -1.7520, -1.7520,  ..., -1.7344, -1.7520, -1.7520],\n",
            "          [-1.7520, -1.7520, -1.7520,  ..., -1.7344, -1.7520, -1.7520]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[   2,    0,  133, 2274,  924,   10,  693,   19,  251, 6219, 2549,  546,\n",
            "         2024,   23,    5, 2280,  136,   10, 2933, 3618,    4,    2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair looking directly at the camera against a dark background.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair looking directly at the camera against a dark background.'}\n",
            "caption_text = a woman with long brown hair looking directly at the camera against a dark background., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[1.7861, 1.7861, 1.7861,  ..., 1.6670, 1.6670, 1.6670],\n",
            "          [1.7861, 1.7861, 1.7861,  ..., 1.6670, 1.6670, 1.6670],\n",
            "          [1.7861, 1.7861, 1.7861,  ..., 1.6670, 1.6670, 1.6670],\n",
            "          ...,\n",
            "          [1.5811, 1.5811, 1.5811,  ..., 1.2900, 1.3242, 1.3408],\n",
            "          [1.5986, 1.5986, 1.5986,  ..., 1.2900, 1.3242, 1.3408],\n",
            "          [1.5986, 1.5986, 1.5986,  ..., 1.2900, 1.3242, 1.3408]],\n",
            "\n",
            "         [[1.9033, 1.9033, 1.9033,  ..., 1.8506, 1.8506, 1.8506],\n",
            "          [1.9033, 1.9033, 1.9033,  ..., 1.8506, 1.8506, 1.8506],\n",
            "          [1.9033, 1.9033, 1.9033,  ..., 1.8506, 1.8506, 1.8506],\n",
            "          ...,\n",
            "          [1.9385, 1.9385, 1.9385,  ..., 1.2910, 1.3252, 1.3428],\n",
            "          [1.9561, 1.9561, 1.9561,  ..., 1.2910, 1.3252, 1.3428],\n",
            "          [1.9561, 1.9561, 1.9561,  ..., 1.2910, 1.3252, 1.3428]],\n",
            "\n",
            "         [[1.9951, 1.9951, 1.9951,  ..., 1.9258, 1.9258, 1.9258],\n",
            "          [1.9951, 1.9951, 1.9951,  ..., 1.9258, 1.9258, 1.9258],\n",
            "          [1.9951, 1.9951, 1.9951,  ..., 1.9258, 1.9258, 1.9258],\n",
            "          ...,\n",
            "          [2.1875, 2.1875, 2.1875,  ..., 1.3506, 1.3848, 1.4023],\n",
            "          [2.2051, 2.2051, 2.2051,  ..., 1.3506, 1.3848, 1.4023],\n",
            "          [2.2051, 2.2051, 2.2051,  ..., 1.3506, 1.3848, 1.4023]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    19,   251,  6219,\n",
            "          2549,  2498,    10,  6907, 11689,   299,   136,    10,  1104,  3618,\n",
            "             4,   264,    16, 16987,   141,     7,   120,  7495,     9,  2933,\n",
            "         13820,   223,    69,  2473,     4,     2]], device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair wearing a pink bra top against a white background. She is demonstrating how to get rid of dark circles under her eyes.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair wearing a pink bra top against a white background. She is demonstrating how to get rid of dark circles under her eyes.'}\n",
            "caption_text = a woman with long brown hair wearing a pink bra top against a white background. She is demonstrating how to get rid of dark circles under her eyes., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.8848, -0.8848, -0.8677,  ...,  0.0569,  0.0569,  0.0569],\n",
            "          [-0.8848, -0.8848, -0.8677,  ...,  0.0569,  0.0569,  0.0569],\n",
            "          [-0.8848, -0.8848, -0.8677,  ...,  0.0740,  0.0740,  0.0740],\n",
            "          ...,\n",
            "          [ 0.9644,  0.9644,  0.9814,  ...,  0.6221,  0.6221,  0.6221],\n",
            "          [ 0.9814,  0.9814,  0.9990,  ...,  0.6392,  0.6392,  0.6392],\n",
            "          [ 0.9814,  0.9814,  0.9990,  ...,  0.6392,  0.6392,  0.6392]],\n",
            "\n",
            "         [[-0.9150, -0.9150, -0.8979,  ...,  0.1876,  0.1876,  0.1876],\n",
            "          [-0.9150, -0.9150, -0.8979,  ...,  0.1876,  0.1876,  0.1876],\n",
            "          [-0.9150, -0.9150, -0.8979,  ...,  0.2052,  0.2052,  0.2052],\n",
            "          ...,\n",
            "          [ 1.1855,  1.1855,  1.2031,  ...,  0.7656,  0.7656,  0.7656],\n",
            "          [ 1.2031,  1.2031,  1.2207,  ...,  0.7827,  0.7827,  0.7827],\n",
            "          [ 1.2031,  1.2031,  1.2207,  ...,  0.7827,  0.7827,  0.7827]],\n",
            "\n",
            "         [[-0.8809, -0.8809, -0.8633,  ...,  0.3743,  0.3743,  0.3743],\n",
            "          [-0.8809, -0.8809, -0.8633,  ...,  0.3743,  0.3743,  0.3743],\n",
            "          [-0.8809, -0.8809, -0.8633,  ...,  0.3916,  0.3916,  0.3916],\n",
            "          ...,\n",
            "          [ 1.4551,  1.4551,  1.4727,  ...,  0.9844,  0.9844,  0.9844],\n",
            "          [ 1.4727,  1.4727,  1.4893,  ...,  1.0020,  1.0020,  1.0020],\n",
            "          [ 1.4727,  1.4727,  1.4893,  ...,  1.0020,  1.0020,  1.0020]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    11,    10,  6907,\n",
            "          6013,   299,     8, 10844,  3051,    15,     5,  1929,    19,    10,\n",
            "          6675,    15,    69,   652,     6, 31843,    30,    10,  1109,    15,\n",
            "             5,   314,   526,     9,     5,  2274,   136,    10,  1104,  3618,\n",
            "             4,     2]], device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman in a pink tank top and jeans walking on the floor with a smile on her face, illuminated by a light on the left side of the image against a white background.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman in a pink tank top and jeans walking on the floor with a smile on her face, illuminated by a light on the left side of the image against a white background.'}\n",
            "caption_text = a woman in a pink tank top and jeans walking on the floor with a smile on her face, illuminated by a light on the left side of the image against a white background., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.4397, -0.4568, -0.4226,  ..., -1.7578, -1.7236, -1.7236],\n",
            "          [-0.4397, -0.4739, -0.4397,  ..., -1.7578, -1.7236, -1.7236],\n",
            "          [-0.4739, -0.4739, -0.4397,  ..., -1.7578, -1.7236, -1.7236],\n",
            "          ...,\n",
            "          [-0.9019, -0.9019, -0.9019,  ..., -0.9365, -0.5425, -0.5083],\n",
            "          [-0.8848, -0.8848, -0.8848,  ..., -0.9189, -0.4910, -0.4568],\n",
            "          [-0.8848, -0.8848, -0.8848,  ..., -0.9189, -0.4739, -0.4226]],\n",
            "\n",
            "         [[-0.1099, -0.1625, -0.1449,  ..., -1.8252, -1.7910, -1.7910],\n",
            "          [-0.1274, -0.1625, -0.1625,  ..., -1.8252, -1.7910, -1.7910],\n",
            "          [-0.1625, -0.1799, -0.1625,  ..., -1.8252, -1.7910, -1.7910],\n",
            "          ...,\n",
            "          [-1.3525, -1.3525, -1.3525,  ..., -1.4053, -0.9502, -0.8979],\n",
            "          [-1.3350, -1.3350, -1.3350,  ..., -1.4053, -0.8979, -0.8452],\n",
            "          [-1.3350, -1.3350, -1.3350,  ..., -1.3701, -0.8804, -0.8101]],\n",
            "\n",
            "         [[-0.1661, -0.2184, -0.2184,  ..., -1.6826, -1.6475, -1.6475],\n",
            "          [-0.1835, -0.2184, -0.2358,  ..., -1.6826, -1.6475, -1.6475],\n",
            "          [-0.2184, -0.2358, -0.2358,  ..., -1.6826, -1.6475, -1.6475],\n",
            "          ...,\n",
            "          [-1.4902, -1.4902, -1.4902,  ..., -1.5078, -1.0205, -0.9502],\n",
            "          [-1.4736, -1.4736, -1.4736,  ..., -1.4561, -0.9678, -0.8809],\n",
            "          [-1.4736, -1.4736, -1.4736,  ..., -1.4561, -0.9331, -0.8286]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   593,    62,     9,    10,\n",
            "           693,    19,   251,  6219,  2549,     8,  6219,  2473,     6,    69,\n",
            "           652,    11,  1056,   150,     5,  3618,    16, 34186,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a close up of a woman with long brown hair and brown eyes, her face in focus while the background is blurred.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a close up of a woman with long brown hair and brown eyes, her face in focus while the background is blurred.'}\n",
            "caption_text = a close up of a woman with long brown hair and brown eyes, her face in focus while the background is blurred., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[0.3311, 0.3311, 0.3481,  ..., 0.2966, 0.2966, 0.2966],\n",
            "          [0.3311, 0.3311, 0.3481,  ..., 0.2966, 0.2966, 0.2966],\n",
            "          [0.3311, 0.3311, 0.3481,  ..., 0.3137, 0.3137, 0.3137],\n",
            "          ...,\n",
            "          [0.1940, 0.1940, 0.2111,  ..., 0.0569, 0.0569, 0.0569],\n",
            "          [0.1940, 0.1940, 0.2111,  ..., 0.0398, 0.0227, 0.0227],\n",
            "          [0.1940, 0.1940, 0.2111,  ..., 0.0398, 0.0227, 0.0227]],\n",
            "\n",
            "         [[0.4502, 0.4502, 0.4678,  ..., 0.3977, 0.3977, 0.3977],\n",
            "          [0.4502, 0.4502, 0.4678,  ..., 0.3977, 0.3977, 0.3977],\n",
            "          [0.4502, 0.4502, 0.4678,  ..., 0.4153, 0.4153, 0.4153],\n",
            "          ...,\n",
            "          [0.5205, 0.5205, 0.5376,  ..., 0.1527, 0.1527, 0.1527],\n",
            "          [0.5205, 0.5205, 0.5376,  ..., 0.1351, 0.1177, 0.1177],\n",
            "          [0.5205, 0.5205, 0.5376,  ..., 0.1351, 0.1177, 0.1177]],\n",
            "\n",
            "         [[0.3044, 0.3044, 0.3220,  ..., 0.2522, 0.2522, 0.2522],\n",
            "          [0.3044, 0.3044, 0.3220,  ..., 0.2522, 0.2522, 0.2522],\n",
            "          [0.3044, 0.3044, 0.3220,  ..., 0.2695, 0.2695, 0.2695],\n",
            "          ...,\n",
            "          [0.7749, 0.7749, 0.7925,  ..., 0.1476, 0.1476, 0.1476],\n",
            "          [0.7749, 0.7749, 0.7925,  ..., 0.1302, 0.1128, 0.1128],\n",
            "          [0.7749, 0.7749, 0.7925,  ..., 0.1302, 0.1128, 0.1128]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,     0,   133,  2274,   924,    10,   693,    19,   251,\n",
            "          6219,  2549,  2498,    10,  6907,  3588,     6,  2934,    11,   760,\n",
            "             9,    10,  2204,     4,   264,    16,  2498,    10,  2007,   648,\n",
            "         14160,  7490,     6,  1969,    13,     5,  2428,   191,     4,  1405,\n",
            "          2549,    16, 25845,    11,    10,   169,    14, 16420,    69,   652,\n",
            "             8,  3639,    10,  2842,     9, 32595,     7,    69,   356,     4,\n",
            "             2]], device='cuda:0')\n",
            "generated_text: </s><s><s>The image shows a woman with long brown hair wearing a pink dress, standing in front of a wall. She is wearing a simple yet stylish outfit, perfect for the spring season. Her hair is styled in a way that frames her face and adds a touch of elegance to her look.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair wearing a pink dress, standing in front of a wall. She is wearing a simple yet stylish outfit, perfect for the spring season. Her hair is styled in a way that frames her face and adds a touch of elegance to her look.'}\n",
            "caption_text = a woman with long brown hair wearing a pink dress, standing in front of a wall. She is wearing a simple yet stylish outfit, perfect for the spring season. Her hair is styled in a way that frames her face and adds a touch of elegance to her look., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[ 0.0912,  0.0912,  0.1083,  ..., -0.1315, -0.1315, -0.1315],\n",
            "          [ 0.0912,  0.0912,  0.1083,  ..., -0.1315, -0.1315, -0.1315],\n",
            "          [ 0.0912,  0.0912,  0.1083,  ..., -0.1315, -0.1315, -0.1315],\n",
            "          ...,\n",
            "          [-0.1656, -0.1656, -0.1656,  ..., -0.6450, -0.6621, -0.6621],\n",
            "          [-0.1656, -0.1656, -0.1656,  ..., -0.6450, -0.6621, -0.6621],\n",
            "          [-0.1656, -0.1656, -0.1656,  ..., -0.6450, -0.6621, -0.6621]],\n",
            "\n",
            "         [[ 0.2578,  0.2578,  0.2751,  ...,  0.0651,  0.0651,  0.0651],\n",
            "          [ 0.2578,  0.2578,  0.2751,  ...,  0.0651,  0.0651,  0.0651],\n",
            "          [ 0.2578,  0.2578,  0.2751,  ...,  0.0651,  0.0651,  0.0651],\n",
            "          ...,\n",
            "          [ 0.0476,  0.0476,  0.0476,  ..., -1.1953, -1.2129, -1.2129],\n",
            "          [ 0.0476,  0.0476,  0.0476,  ..., -1.1953, -1.2129, -1.2129],\n",
            "          [ 0.0476,  0.0476,  0.0476,  ..., -1.1953, -1.2129, -1.2129]],\n",
            "\n",
            "         [[ 0.2347,  0.2347,  0.2522,  ..., -0.0092, -0.0092, -0.0092],\n",
            "          [ 0.2347,  0.2347,  0.2522,  ..., -0.0092, -0.0092, -0.0092],\n",
            "          [ 0.2347,  0.2347,  0.2522,  ..., -0.0092, -0.0092, -0.0092],\n",
            "          ...,\n",
            "          [ 0.1650,  0.1650,  0.1650,  ..., -1.3691, -1.3857, -1.3857],\n",
            "          [ 0.1650,  0.1650,  0.1650,  ..., -1.3691, -1.3857, -1.3857],\n",
            "          [ 0.1650,  0.1650,  0.1650,  ..., -1.3691, -1.3857, -1.3857]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    19,   251,  6219,\n",
            "          2549,  2498,    10,  6907,  3588,     8,    10,  1763,     9,  4334,\n",
            "          5567, 19706,     4,    20,  3618,    16,  2829, 34186,     6,  1311,\n",
            "             5,  2274,    10,  3366,   219,   619,     4,     2]],\n",
            "       device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair wearing a pink dress and a pair of silver earrings. The background is slightly blurred, giving the image a dreamy feel.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair wearing a pink dress and a pair of silver earrings. The background is slightly blurred, giving the image a dreamy feel.'}\n",
            "caption_text = a woman with long brown hair wearing a pink dress and a pair of silver earrings. The background is slightly blurred, giving the image a dreamy feel., concept_sentence=K3rryN30n\n",
            "K3rryN30n\n",
            "inputs {'input_ids': tensor([[    0, 47066, 21700,    11,  4617,    99,    16,  2343,    11,     5,\n",
            "          2274,     4,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[[[-0.6279, -0.6450, -0.6108,  ..., -0.6792, -0.6792, -0.7139],\n",
            "          [-0.6279, -0.6108, -0.6279,  ..., -0.6968, -0.6792, -0.6792],\n",
            "          [-0.6108, -0.6108, -0.6279,  ..., -0.6792, -0.6621, -0.7139],\n",
            "          ...,\n",
            "          [ 1.3584,  1.3760,  1.4102,  ..., -1.0732, -1.0215, -0.9707],\n",
            "          [ 1.3926,  1.3926,  1.4443,  ..., -1.0732, -1.0391, -0.9707],\n",
            "          [ 1.3926,  1.3760,  1.4268,  ..., -1.0566, -1.0391, -1.0049]],\n",
            "\n",
            "         [[-0.4602, -0.4775, -0.4602,  ..., -0.6353, -0.6177, -0.6353],\n",
            "          [-0.4602, -0.4426, -0.4602,  ..., -0.6353, -0.6353, -0.6353],\n",
            "          [-0.4426, -0.4602, -0.4426,  ..., -0.6177, -0.6353, -0.6353],\n",
            "          ...,\n",
            "          [ 0.7305,  0.7305,  0.7480,  ..., -1.4756, -1.3877, -1.2832],\n",
            "          [ 0.7480,  0.7305,  0.7656,  ..., -1.4580, -1.3701, -1.3008],\n",
            "          [ 0.7305,  0.7480,  0.7656,  ..., -1.5107, -1.4053, -1.2832]],\n",
            "\n",
            "         [[-0.4624, -0.4624, -0.4451,  ..., -0.7236, -0.7065, -0.7065],\n",
            "          [-0.4451, -0.4451, -0.4624,  ..., -0.7065, -0.7236, -0.7236],\n",
            "          [-0.4451, -0.4275, -0.4451,  ..., -0.6890, -0.6714, -0.6890],\n",
            "          ...,\n",
            "          [ 0.2695,  0.3044,  0.3394,  ..., -1.5605, -1.4902, -1.3340],\n",
            "          [ 0.2522,  0.2871,  0.3567,  ..., -1.5430, -1.4561, -1.3516],\n",
            "          [ 0.2871,  0.2871,  0.3394,  ..., -1.5605, -1.4736, -1.3340]]]],\n",
            "       device='cuda:0', dtype=torch.float16)}\n",
            "generated_ids tensor([[    2,     0,   133,  2274,   924,    10,   693,    19,   251,  6219,\n",
            "          2549, 12382,    23,     5,  2280,   136,    10, 34186,  3618,     4,\n",
            "             2]], device='cuda:0')\n",
            "generated_text: </s><s>The image shows a woman with long brown hair smiling at the camera against a blurred background.</s>\n",
            "parsed_answer = {'<DETAILED_CAPTION>': 'The image shows a woman with long brown hair smiling at the camera against a blurred background.'}\n",
            "caption_text = a woman with long brown hair smiling at the camera against a blurred background., concept_sentence=K3rryN30n\n",
            "Creating dataset\n",
            "resize datasets/kerry-neon/Kerry00023.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00023.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00023.txt, original_caption=K3rryN30n a woman standing against a white background wearing a dusty rose ribbed tank top and black pants. The tank top has a scoop neckline and thin straps, and the fabric has a soft, ribbed texture.\n",
            "resize datasets/kerry-neon/Kerry00022.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00022.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00022.txt, original_caption=K3rryN30n a woman in a pink dress sitting on a couch, with a wall in the background. She is wearing makeup, which is one of the 10 best makeup looks for every skin tone. Her eyes are highlighted with a subtle smoky eye look, her lips are painted a glossy pink, and her cheeks are contoured with a light pink blush. Her hair is styled in loose waves, and she is wearing minimal makeup.\n",
            "resize datasets/kerry-neon/Kerry00015.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00015.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00015.txt, original_caption=K3rryN30n a woman in a pink tank top and black shorts posing for a picture against a white background. She appears to be in the middle of a yoga session, with her arms outstretched and her head tilted slightly to the side. Her hair is pulled back in a ponytail and she has a peaceful expression on her face.\n",
            "resize datasets/kerry-neon/Kerry00014.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00014.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00014.txt, original_caption=K3rryN30n a woman in a pink tank top and blue jeans with her hands outstretched, standing in front of a wall. She appears to be in the middle of an interview, as indicated by the title of the image.\n",
            "resize datasets/kerry-neon/Kerry00013.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00013.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00013.txt, original_caption=K3rryN30n a woman in a pink dress smiling at the camera against a white background. She is identified as Jessica Alba, and the image was taken by a professional photographer.\n",
            "resize datasets/kerry-neon/Kerry00010.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00010.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00010.txt, original_caption=K3rryN30n a woman with long brown hair wearing a black top, standing in front of a wall. She appears to be in the middle of an interview, as indicated by the title of the image.\n",
            "resize datasets/kerry-neon/Kerry00009.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00009.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00009.txt, original_caption=K3rryN30n a woman with long brown hair looking directly at the camera against a dark background.\n",
            "resize datasets/kerry-neon/Kerry00007.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00007.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00007.txt, original_caption=K3rryN30n a woman with long brown hair wearing a pink bra top against a white background. She is demonstrating how to get rid of dark circles under her eyes.\n",
            "resize datasets/kerry-neon/Kerry00005.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00005.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00005.txt, original_caption=K3rryN30n a woman in a pink tank top and jeans walking on the floor with a smile on her face, illuminated by a light on the left side of the image against a white background.\n",
            "resize datasets/kerry-neon/Kerry00004.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00004.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00004.txt, original_caption=K3rryN30n a close up of a woman with long brown hair and brown eyes, her face in focus while the background is blurred.\n",
            "resize datasets/kerry-neon/Kerry00003.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00003.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00003.txt, original_caption=K3rryN30n a woman with long brown hair wearing a pink dress, standing in front of a wall. She is wearing a simple yet stylish outfit, perfect for the spring season. Her hair is styled in a way that frames her face and adds a touch of elegance to her look.\n",
            "resize datasets/kerry-neon/Kerry00002.jpg : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00002.jpg, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00002.txt, original_caption=K3rryN30n a woman with long brown hair wearing a pink dress and a pair of silver earrings. The background is slightly blurred, giving the image a dreamy feel.\n",
            "resize datasets/kerry-neon/Kerry00001.png : 1024x1024\n",
            "image_path=datasets/kerry-neon/Kerry00001.png, caption_path = /content/fluxgym-Colab/datasets/kerry-neon/Kerry00001.txt, original_caption=K3rryN30n a woman with long brown hair smiling at the camera against a blurred background.\n",
            "destination_folder datasets/kerry-neon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty placeholder files\n",
        "%cd /content/fluxgym-Colab/models/clip\n",
        "!touch t5xxl_fp8.safetensors\n",
        "\n",
        "%cd /content/fluxgym-Colab/models/vae\n",
        "!touch ae.sft"
      ],
      "metadata": {
        "id": "Oe0hecgAkYLU",
        "outputId": "83b96d81-912b-4396-cbfc-0f354f560f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab/models/clip\n",
            "/content/fluxgym-Colab/models/vae\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the models directory structure\n",
        "!mkdir -p /content/fluxgym-Colab/models/unet\n",
        "!mkdir -p /content/fluxgym-Colab/models/clip\n",
        "!mkdir -p /content/fluxgym-Colab/models/vae\n",
        "\n",
        "# Download the required Flux models (this will take a few minutes)\n",
        "%cd /content/fluxgym-Colab/models/unet\n",
        "!wget https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8.safetensors\n",
        "\n",
        "%cd /content/fluxgym-Colab/models/clip\n",
        "!wget https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors\n",
        "!wget https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8.safetensors\n",
        "\n",
        "%cd /content/fluxgym-Colab/models/vae\n",
        "!wget https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/ae.sft"
      ],
      "metadata": {
        "id": "OtY5dbdNiBMO",
        "outputId": "f7eb3902-3700-4132-b1eb-7c8bf98ab649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab/models/unet\n",
            "--2025-06-20 22:49:12--  https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.16, 18.239.50.80, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/fa/7f/fa7f815f89d4b2bcb4ae950e05293cb2f1e1621038b996c0a9829dbdf2a8da85/1be961341be8f5307ef26c787199f80bf4e0de3c1c0b4617095aa6ee5550dfce?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27flux1-dev-fp8.safetensors%3B+filename%3D%22flux1-dev-fp8.safetensors%22%3B&Expires=1750463353&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MzM1M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2ZhLzdmL2ZhN2Y4MTVmODlkNGIyYmNiNGFlOTUwZTA1MjkzY2IyZjFlMTYyMTAzOGI5OTZjMGE5ODI5ZGJkZjJhOGRhODUvMWJlOTYxMzQxYmU4ZjUzMDdlZjI2Yzc4NzE5OWY4MGJmNGUwZGUzYzFjMGI0NjE3MDk1YWE2ZWU1NTUwZGZjZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=LQXLuKKOqJw-l5nf%7E%7Efq18opDOYzHHRPy6aFAbJAtclHelmyRQzfKkpNnA3BAZdQyt99RiWMWM78NKWsS25pf5N24TaSmEWBaPHBpmAxW8-KTsL8qWyN5JbD%7ERjMn9%7E1LVQj08XNMgh1214XAHYfz7A4jGH9y98HrvZH1JFS1swEiXovjpQcPijlSgPT9T8mG9nx8%7EgaJoiDRZSfufgOgdMNIiE%7Eyz89MNrWiFWJB-oN8RIChjG6TVZa%7EgPIitoPeKb3QDgIKQORyUnCnzf8aLFjzqI0ICWz%7EIovOEozrgd9Xtb1JIKMQjhjCtXDtKxsp7kIjxc7Uhm90MbvDClEkg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-06-20 22:49:13--  https://cdn-lfs-us-1.hf.co/repos/fa/7f/fa7f815f89d4b2bcb4ae950e05293cb2f1e1621038b996c0a9829dbdf2a8da85/1be961341be8f5307ef26c787199f80bf4e0de3c1c0b4617095aa6ee5550dfce?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27flux1-dev-fp8.safetensors%3B+filename%3D%22flux1-dev-fp8.safetensors%22%3B&Expires=1750463353&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MzM1M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2ZhLzdmL2ZhN2Y4MTVmODlkNGIyYmNiNGFlOTUwZTA1MjkzY2IyZjFlMTYyMTAzOGI5OTZjMGE5ODI5ZGJkZjJhOGRhODUvMWJlOTYxMzQxYmU4ZjUzMDdlZjI2Yzc4NzE5OWY4MGJmNGUwZGUzYzFjMGI0NjE3MDk1YWE2ZWU1NTUwZGZjZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=LQXLuKKOqJw-l5nf%7E%7Efq18opDOYzHHRPy6aFAbJAtclHelmyRQzfKkpNnA3BAZdQyt99RiWMWM78NKWsS25pf5N24TaSmEWBaPHBpmAxW8-KTsL8qWyN5JbD%7ERjMn9%7E1LVQj08XNMgh1214XAHYfz7A4jGH9y98HrvZH1JFS1swEiXovjpQcPijlSgPT9T8mG9nx8%7EgaJoiDRZSfufgOgdMNIiE%7Eyz89MNrWiFWJB-oN8RIChjG6TVZa%7EgPIitoPeKb3QDgIKQORyUnCnzf8aLFjzqI0ICWz%7EIovOEozrgd9Xtb1JIKMQjhjCtXDtKxsp7kIjxc7Uhm90MbvDClEkg__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.239.36.68, 18.239.36.126, 18.239.36.52, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.239.36.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11901525888 (11G) [binary/octet-stream]\n",
            "Saving to: ‘flux1-dev-fp8.safetensors’\n",
            "\n",
            "flux1-dev-fp8.safet 100%[===================>]  11.08G   233MB/s    in 69s     \n",
            "\n",
            "2025-06-20 22:50:21 (165 MB/s) - ‘flux1-dev-fp8.safetensors’ saved [11901525888/11901525888]\n",
            "\n",
            "/content/fluxgym-Colab/models/clip\n",
            "--2025-06-20 22:50:23--  https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.16, 18.239.50.103, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/f0/72/f072b3fc381065339926f6194e8ae71b6a464d596c9495100c3c8730729ec94e/660c6f5b1abae9dc498ac2d21e1347d2abdb0cf6c0c0c8576cd796491d9a6cdd?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27clip_l.safetensors%3B+filename%3D%22clip_l.safetensors%22%3B&Expires=1750463423&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MzQyM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2YwLzcyL2YwNzJiM2ZjMzgxMDY1MzM5OTI2ZjYxOTRlOGFlNzFiNmE0NjRkNTk2Yzk0OTUxMDBjM2M4NzMwNzI5ZWM5NGUvNjYwYzZmNWIxYWJhZTlkYzQ5OGFjMmQyMWUxMzQ3ZDJhYmRiMGNmNmMwYzBjODU3NmNkNzk2NDkxZDlhNmNkZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=eVgVzK637xMIpCJm4uOX0plzwqpuVmXIiL0W-l3wsTYw76CwanJ6XMwtqOcnayJW3O4%7Ecr3kkdNezG3youKjW0jvGyZuIjAUOoiS73RbddDIZRmMIjm16ILw%7Ex3ZA-SnkfxfVzMQ6VYn-hunhKxwn%7Egj8l5QZsS5qZRVpNtNr2HTkX0lpXhVmtroorX1uR23GUuAZRQoa-VbxS5gHWV1CNoohBGylQM-xAzdVF9atamsVxnZrfsxKoMW2OLRRBTEwKzrhL8UW1JVkiwkUoJAoWvK54xFZ3LzpJ-%7ExyOegAYf81PY-ViGY4tPNTXQix4e%7E82zfYvFJaoW4P1TqkI62w__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-06-20 22:50:23--  https://cdn-lfs-us-1.hf.co/repos/f0/72/f072b3fc381065339926f6194e8ae71b6a464d596c9495100c3c8730729ec94e/660c6f5b1abae9dc498ac2d21e1347d2abdb0cf6c0c0c8576cd796491d9a6cdd?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27clip_l.safetensors%3B+filename%3D%22clip_l.safetensors%22%3B&Expires=1750463423&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MzQyM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2YwLzcyL2YwNzJiM2ZjMzgxMDY1MzM5OTI2ZjYxOTRlOGFlNzFiNmE0NjRkNTk2Yzk0OTUxMDBjM2M4NzMwNzI5ZWM5NGUvNjYwYzZmNWIxYWJhZTlkYzQ5OGFjMmQyMWUxMzQ3ZDJhYmRiMGNmNmMwYzBjODU3NmNkNzk2NDkxZDlhNmNkZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=eVgVzK637xMIpCJm4uOX0plzwqpuVmXIiL0W-l3wsTYw76CwanJ6XMwtqOcnayJW3O4%7Ecr3kkdNezG3youKjW0jvGyZuIjAUOoiS73RbddDIZRmMIjm16ILw%7Ex3ZA-SnkfxfVzMQ6VYn-hunhKxwn%7Egj8l5QZsS5qZRVpNtNr2HTkX0lpXhVmtroorX1uR23GUuAZRQoa-VbxS5gHWV1CNoohBGylQM-xAzdVF9atamsVxnZrfsxKoMW2OLRRBTEwKzrhL8UW1JVkiwkUoJAoWvK54xFZ3LzpJ-%7ExyOegAYf81PY-ViGY4tPNTXQix4e%7E82zfYvFJaoW4P1TqkI62w__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.239.83.59, 18.239.83.13, 18.239.83.30, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.239.83.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 246144152 (235M) [binary/octet-stream]\n",
            "Saving to: ‘clip_l.safetensors.1’\n",
            "\n",
            "clip_l.safetensors. 100%[===================>] 234.74M  80.2MB/s    in 2.9s    \n",
            "\n",
            "2025-06-20 22:50:26 (80.2 MB/s) - ‘clip_l.safetensors.1’ saved [246144152/246144152]\n",
            "\n",
            "--2025-06-20 22:50:26--  https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.16, 18.239.50.49, 18.239.50.103, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-06-20 22:50:26 ERROR 404: Not Found.\n",
            "\n",
            "/content/fluxgym-Colab/models/vae\n",
            "--2025-06-20 22:50:26--  https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/ae.sft\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.16, 18.239.50.49, 18.239.50.80, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "\n",
            "Username/Password Authentication Failed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the T5 text encoder (correct URL)\n",
        "%cd /content/fluxgym-Colab/models/clip\n",
        "!wget https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8.safetensors\n",
        "\n",
        "# If that fails, try this alternative:\n",
        "!wget https://huggingface.co/Kijai/flux-fp8/resolve/main/t5xxl_fp8.safetensors\n",
        "\n",
        "# Fix the VAE (correct filename)\n",
        "%cd /content/fluxgym-Colab/models/vae\n",
        "!wget https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/ae.safetensors\n",
        "\n",
        "# Rename it to what FluxGym expects\n",
        "!mv ae.safetensors ae.sft"
      ],
      "metadata": {
        "id": "loeFw8pFijEL",
        "outputId": "dca74d9a-4e73-4880-c1d2-cf5bd3f0ad43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab/models/clip\n",
            "--2025-06-20 22:51:31--  https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-06-20 22:51:31 ERROR 404: Not Found.\n",
            "\n",
            "--2025-06-20 22:51:31--  https://huggingface.co/Kijai/flux-fp8/resolve/main/t5xxl_fp8.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-06-20 22:51:31 ERROR 404: Not Found.\n",
            "\n",
            "/content/fluxgym-Colab/models/vae\n",
            "--2025-06-20 22:51:31--  https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/ae.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.103, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "\n",
            "Username/Password Authentication Failed.\n",
            "mv: cannot stat 'ae.safetensors': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the T5 text encoder from the correct location\n",
        "%cd /content/fluxgym-Colab/models/clip\n",
        "!wget https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder_2.safetensors -O t5xxl_fp8.safetensors\n",
        "\n",
        "# If that doesn't work, try this alternative:\n",
        "!wget https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/t5xxl_fp8.safetensors\n",
        "\n",
        "# Get the VAE from a public mirror\n",
        "%cd /content/fluxgym-Colab/models/vae\n",
        "!wget https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/ae.sft\n",
        "\n",
        "# Alternative VAE source:\n",
        "!wget https://huggingface.co/comfyanonymous/flux_vae/resolve/main/ae.safetensors -O ae.sft"
      ],
      "metadata": {
        "id": "qjJma0f7izGA",
        "outputId": "ecf82610-5d4f-4274-ab51-3d9d9e43bd0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fluxgym-Colab/models/clip\n",
            "--2025-06-20 22:52:37--  https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder_2.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "\n",
            "Username/Password Authentication Failed.\n",
            "--2025-06-20 22:52:37--  https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/t5xxl_fp8.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.16, 18.239.50.49, 18.239.50.80, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-06-20 22:52:37 ERROR 404: Not Found.\n",
            "\n",
            "/content/fluxgym-Colab/models/vae\n",
            "--2025-06-20 22:52:37--  https://huggingface.co/cocktailpeanut/xulf-dev/resolve/main/ae.sft\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.103, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/e6/1b/e61b51323e49f08f24e9281f70900db08a8c978b7ad4a4ec5c21b72296a4214b/afc8e28272cd15db3919bacdb6918ce9c1ed22e96cb12c4d5ed0fba823529e38?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ae.sft%3B+filename%3D%22ae.sft%22%3B&Expires=1750463557&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MzU1N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U2LzFiL2U2MWI1MTMyM2U0OWYwOGYyNGU5MjgxZjcwOTAwZGIwOGE4Yzk3OGI3YWQ0YTRlYzVjMjFiNzIyOTZhNDIxNGIvYWZjOGUyODI3MmNkMTVkYjM5MTliYWNkYjY5MThjZTljMWVkMjJlOTZjYjEyYzRkNWVkMGZiYTgyMzUyOWUzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Wjz7G6jVQ-pJr3-rD2CGGjEVpe0mBkLQhxYemAZgcO381sOiDU-SQqnFuh7PWCbs10Uop8%7EmLCEFfYDT2Y9y6zV3lD1Ofi7KB4q6NkLECRwyIWz7nxea60WjUogNjZJ0%7EBi8-sSk8x4XPbFbvWRRdiTQbLP7Ys4o2-qV1CYg-zqC08vxmGgSvwxcTk-sWaTP7bh9kWMpF%7EksKidksKVArMYENd6l8yHyVgcd2VqiaDSoBB%7EgIoXwVBtOA33wO%7EERrMGKN77gAYNHZLAT1TCy%7Ey2mGCHGBFr-NrtJAsZzjlEoZmWS8J6xbBtrZ84QI5EBcobz0ANFsefNvJlQQlwdhw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-06-20 22:52:37--  https://cdn-lfs-us-1.hf.co/repos/e6/1b/e61b51323e49f08f24e9281f70900db08a8c978b7ad4a4ec5c21b72296a4214b/afc8e28272cd15db3919bacdb6918ce9c1ed22e96cb12c4d5ed0fba823529e38?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ae.sft%3B+filename%3D%22ae.sft%22%3B&Expires=1750463557&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDQ2MzU1N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U2LzFiL2U2MWI1MTMyM2U0OWYwOGYyNGU5MjgxZjcwOTAwZGIwOGE4Yzk3OGI3YWQ0YTRlYzVjMjFiNzIyOTZhNDIxNGIvYWZjOGUyODI3MmNkMTVkYjM5MTliYWNkYjY5MThjZTljMWVkMjJlOTZjYjEyYzRkNWVkMGZiYTgyMzUyOWUzOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Wjz7G6jVQ-pJr3-rD2CGGjEVpe0mBkLQhxYemAZgcO381sOiDU-SQqnFuh7PWCbs10Uop8%7EmLCEFfYDT2Y9y6zV3lD1Ofi7KB4q6NkLECRwyIWz7nxea60WjUogNjZJ0%7EBi8-sSk8x4XPbFbvWRRdiTQbLP7Ys4o2-qV1CYg-zqC08vxmGgSvwxcTk-sWaTP7bh9kWMpF%7EksKidksKVArMYENd6l8yHyVgcd2VqiaDSoBB%7EgIoXwVBtOA33wO%7EERrMGKN77gAYNHZLAT1TCy%7Ey2mGCHGBFr-NrtJAsZzjlEoZmWS8J6xbBtrZ84QI5EBcobz0ANFsefNvJlQQlwdhw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.238.243.82, 18.238.243.3, 18.238.243.19, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.238.243.82|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335304388 (320M) [binary/octet-stream]\n",
            "Saving to: ‘ae.sft.1’\n",
            "\n",
            "ae.sft.1            100%[===================>] 319.77M   261MB/s    in 1.2s    \n",
            "\n",
            "2025-06-20 22:52:39 (261 MB/s) - ‘ae.sft.1’ saved [335304388/335304388]\n",
            "\n",
            "--2025-06-20 22:52:39--  https://huggingface.co/comfyanonymous/flux_vae/resolve/main/ae.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.103, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "\n",
            "Username/Password Authentication Failed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tQM2tYxk00i"
      },
      "source": [
        "# **Download the completed Loras from the fluxgym-Colab/outputs directory. Copy and paste the models URL in the filename = 'Lora path here'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8obna2u3ssGv"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "filename = '/content/fluxgym-Colab/outputs/sarah-lora.safetensors'\n",
        "files.download(filename)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}